<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>数据库 on Feng Zhenbing's Blog</title><link>https://fengzhenbing.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/</link><description>Recent content in 数据库 on Feng Zhenbing's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 12 Sep 2020 14:16:25 +0600</lastBuildDate><atom:link href="https://fengzhenbing.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/index.xml" rel="self" type="application/rss+xml"/><item><title>innodb概述及原理</title><link>https://fengzhenbing.github.io/p/innodb%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86/</link><pubDate>Sat, 12 Sep 2020 14:16:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/innodb%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86/</guid><description>Innodb概述 该存储引擎是第一个完整支持ACID事 务的MySOL存储引擎，其特点是行锁设计、支持MVCC、支持外键、提供一致性非锁定读，同时被设计用来最有效地利用以及使用内存和CPU；
体系结构如下：
InnoDB存储引擎有多个内存块，这些内存块组成一个内存池，主要负责如下工作：
维护所有进程、线程需要访问的多个内部数据结构 缓存磁盘上的数据，方便快速读取，同时在对磁盘文件的数据修改之前在这里缓存 重做日志（redo log）缓冲 后台线程的主要作用：
负责刷新内存池中的数据，保证缓冲池中的内存缓存的是最近的数据
将已修改的数据文件刷新到磁盘文件
innodb 内存结构 缓冲池 InnoDB存储引擎是基于磁盘存储的，并将其中的记录按照页的方式进行管理。因此 可将其视为基于磁盘的数据库系统 (Disk-baseDatabase)。在数据库系统中，由于CPU 速度与磁盘速度之间的鸿沟，基于磁盘的数据库系统通常使用缇冲池技术来提高数据库 的整体性能 .
缓冲池简单来说就是一块内存区域，通过内存的速度来弥补磁盘速度较慢对数据库性能的影响。在数据库中进行读取页的操作，首先将从磁盘读到的页存放在缓冲他中 这个过程称为将页“FIX”在缓冲池中。下一次再读相同的页时，首先判断该页是否在 缓冲他中，若在缓冲池中，称该页在缓冲池中被命中，直接读取该页。否则，读取磁盘 上的页 .
对于数据库中页的修改操作，则首先修改在缓冲池中的页，然后再以一定的频率刷 新到磁盘上，这里需要注意的是，页从缓冲池剧新回磁盘的操作并不是在每次页发生更新时触发，而是通过一种称为Checkpoint的机制刷新, 提高据库的整体性能
综上所述，缓冲池的大小 直接影响着数据库的整体性能。
SHOWVARIABLESLIKE&amp;#39;innodb_buffer_poo1_size&amp;#39;\G;缓冲池管理 LRU Free Flush LRU list 通常来说 数据库中的缓冲池是通过LRU (Latest Recent Used， 最近最少使用》 算法来进行管理的, 即最频繁使用的页(一页16k)在LRU列表的前端，而最少使用的页在 LRU列表的尾端, 当缓冲池不能存放新读取到的页时 将首先释放LRU列表中尾 端的页.
Buffer Pool的LRU算法与普通的LRU算法不一样，新数据页插入时并不从头部插入，而是从中间位置插入（默认配置下，该位置从表头计算为列表5/8的位置)，在该位置，列表被分成了如下两个子列表：
在头部是最近被访问的新页列表 在尾部是很少被访问的旧页列表 可以和jvm的young区 old区类比。
为什么这么设计？？ 直接将读取的页放人到LRU列表的首部呢?这是因为若直接将读取到的页放人到LRU的首部，那么某些SQL操作可能会使缓冲池中 的页被刷新出，从而影响缓冲池的效率。常见的这类操作为索引或数据的扫描操作。这 类操作需要访问表中的许多页，甚至是全部的页，而这些页通常来说又仅在这次查询操 作中需要，并不是活跃的热点数据。如果页被放人LRU列表的首部，那么非常可能将 所需要的热点数据页从LRU列表中移除，而在下一次需要读取该页时， InnoDB存储引 肇需要再次访问磁盘</description></item><item><title>数据库日志总结</title><link>https://fengzhenbing.github.io/p/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%97%A5%E5%BF%97%E6%80%BB%E7%BB%93/</link><pubDate>Sat, 12 Sep 2020 14:16:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%97%A5%E5%BF%97%E6%80%BB%E7%BB%93/</guid><description>undo log 是InnoDB存储引擎独有的
想要保证事务的原子性，就需要在异常发生时，对已经执行的操作进行回滚，在 MySQL 中，恢复机制是通过 回滚日志（undo log） 实现的。
Mvcc 多版本的记录在undo log中
redo log 是InnoDB存储引擎独有的物理日志，记录内容是“在某个数据页上做了什么修改”
redo log（重做日志），它让MySQL拥有了崩溃恢复能力。
配合checkpoint循环使用
binlog binlog 是逻辑日志，记录内容是语句的原始逻辑，类似于“给 ID=2 这一行的 c 字段加 1”，属于MySQL Server 层。 二进制目志 (binary log)记录了对MySQL数据库执行更改的所有操作，但是不包 括SELECT和SHOW这类操作，因为这类操作对数据本身并没有修改。 binlog 日志有三种格式，可以通过binlog_format参数指定。
statement row mixed 用途： 恢复 (recovery):某些数据的恢复需要二进制日志，例如，在一个数据库全备文 件恢复后，用户可以通过二进制日志进行point-in-time的恢复
复制 (replication):其原理与恢复类似，通过复制和执行二进制日志使一台远程 的MySQL数据库 (一般称为slave或standby) 与一台MySQL数据库(一般称 /master或primary) 进行实时同步</description></item><item><title>分布式事务</title><link>https://fengzhenbing.github.io/p/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</link><pubDate>Thu, 13 Aug 2020 14:16:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</guid><description>两段式提交 （2 Phase Commit，2PC）
准备阶段 重操作
提交阶段 轻操作
三段式提交 （3 Phase Commit，3PC）
在事务需要回滚的场景中：三段式的性能通常是要比两段式好很多的。
但在事务能够正常提交的场景中：两者的性能都依然很差，甚至三段式因为多了一次询问，还要稍微更差一些。
CanCommit 轻操作
PreCommit 重操作
CanCommit 轻操作
TCC事务 业务侵入性强
加入业务的中间字段
Try confirm 冥等
cancel AT事务 反向sql
MQ消息最终一致性解决方案 事务消息 由于传统的处理方式无法解决消息生成者本地事务处理成功与消息发送成功两者的一致性问题，因此事务消息就诞生了，它实现了消息生成者本地事务与消息发送的原子性，保证了消息生成者本地事务处理成功与消息发送成功的最终一致性问题。
https://www.jianshu.com/p/eb571e4065ec
RocketMQ支持事务消息
生产者先发消息，再执行业务操作： 如果反过来，可能业务执行成功就宕机，消息没发出，导致不一致 事务消息是针对生产端而言的，而消费端，消费端的一致性是通过MQ的重试机制来完成的：消息消费失败的话，MQ自己会负责重推消息，直到消费成功（消费者保证幂等性）。 RocketMQ事务消息原理 MQ存储了待发送的消息，但是MQ无法感知到上游处理的最终结果。对于RocketMQ而言，它的解决方案非常的简单，就是其内部实现会有一个定时任务，去轮训状态为待发送的消息，然后给producer发送check请求，而producer必须实现一个check监听器，监听器的内容通常就是去检查与之对应的本地事务是否成功(一般就是查询DB)，如果成功了，则MQ会将消息设置为可发送，否则就删除消息。</description></item></channel></rss>