<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Feng Zhenbing's Blog</title><link>https://fengzhenbing.github.io/post/</link><description>Recent content in Posts on Feng Zhenbing's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 05 Sep 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://fengzhenbing.github.io/post/index.xml" rel="self" type="application/rss+xml"/><item><title>shardingsphere（5.0.0.beta）元数据上下文</title><link>https://fengzhenbing.github.io/p/shardingsphere5.0.0.beta%E5%85%83%E6%95%B0%E6%8D%AE%E4%B8%8A%E4%B8%8B%E6%96%87/</link><pubDate>Sun, 05 Sep 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/shardingsphere5.0.0.beta%E5%85%83%E6%95%B0%E6%8D%AE%E4%B8%8A%E4%B8%8B%E6%96%87/</guid><description>Shardingsphere（5.0.0.beta）源码学习-元数据上下文 上下文对象 上下文对象作为读取并解析配置, 承载数据的核心；
spring有ApplicationContext,netty有HandlerContext
向其他中间件一样，在ShardingSphere也十分重要; 后续几乎所有功能比如数据分片、数据加密、SQL 改写，各类扩展都依赖上下文对象存储的数据
标准元数据上下文 StandardMetaDataContexts 核心存储了ShardingSphereMetaData元数据集合，作为重点后面分析
@Getter public final class StandardMetaDataContexts implements MetaDataContexts { // 元数据集合 private final Map&amp;lt;String, ShardingSphereMetaData&amp;gt; metaDataMap; private final ShardingSphereRuleMetaData globalRuleMetaData; // 执行引擎 private final ExecutorEngine executorEngine; //优化引擎上下文工厂 private final OptimizeContextFactory optimizeContextFactory; private final ConfigurationProperties props; // 状态上下文 private final StateContext stateContext; ... } 治理元数据上下文 StandardMetaDataContexts 其实也是用的标准的StandardMetaDataContexts，治理模块shardingsphere-governance使用该上下文，通过配置中心读取规则配置，
注入到StandardMetaDataContexts中，GovernanceFacade是配置中心的门面模式，目前支持了zookeeper和etcd,其实还可以通过RegistryCenterRepository的spi实现其他的配置中心，比如nacos, apollo,consul等。
public final class GovernanceMetaDataContexts implements MetaDataContexts { //治理： 配置中心的门面模式 private final GovernanceFacade governanceFacade; //还是使用StandardMetaDataContexts 装饰器模式 private volatile StandardMetaDataContexts metaDataContexts; private final ShardingSphereLock lock; .</description></item><item><title>shardingsphere（5.0.0.beta）源码总览</title><link>https://fengzhenbing.github.io/p/shardingsphere5.0.0.beta%E6%BA%90%E7%A0%81%E6%80%BB%E8%A7%88/</link><pubDate>Thu, 02 Sep 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/shardingsphere5.0.0.beta%E6%BA%90%E7%A0%81%E6%80%BB%E8%A7%88/</guid><description>Shardingsphere（5.0.0.beta）源码学习-总览 shardingsphere作为极为优秀的开源分布式数据库解决方案，通过阅读源码可以学到很多软件设计与开发的知识。
本次我继续按照之前读源码的方式从整体到细节，带着问题读源码的方式记录这次深入学习 shardingsphere的过程。
源码版本 5.0.0.beta 官方文档 源码地址 https://github.com/apache/shardingsphere/tree/5.0.0-beta 项目结构 先大概理解各个模块的主要功能点
一级目录 说明 examples 各种使用例子 shardingsphere-agent 监控, 对接apm,链路追踪 shardingsphere-db-protocol 数据库协议 shardingsphere-distribution 相关打包发步用 shardingsphere-distsql-parser distsql新功能:ShardingSphere 特有的内置 SQL 语言，提供了标准 SQL 之外的增量功能操作能力。 shardingsphere-features 常用功能shardingsphere-db-discovery 基于MGR主从切换的功能shardingsphere-encrypt 加解密shardingsphere-readwrite-splitting 读写分离 **重点**shardingsphere-shadow 影子库shardingsphere-sharding 分库分表 **重点** shardingsphere-governance 数据治理：结合注册中心，提供给前端页面使用 shardingsphere-infra 引擎内核：shardingsphere-infra-authority proxy的权限控制shardingsphere-infra-binder sql解析后的结果绑定封装SQLStatement封装为各类上下文contextshardingsphere-infra-common 重要的实体类及工具 的元数据metadata,SPI,yaml工具，rule接口等shardingsphere-infra-context 上下文相关shardingsphere-infra-datetime 时间服务shardingsphere-infra-executor 执行器引擎 **重点**shardingsphere-infra-merge 归并引擎**重点**shardingsphere-infra-optimize 优化引擎**重点**shardingsphere-infra-parser 解析引擎**重点**shardingsphere-infra-rewrite 改写引擎**重点**shardingsphere-infra-route 路由引擎**重点** shardingsphere-jdbc jdbc核心功能：增强版的 JDBC 驱动，完全兼容 JDBC 和各种 ORM 框架。装饰器模式，对原生的DataSource,Connection,Statement(PrepareStatement),ResultSet进行包装， shardingsphere-proxy 透明化的数据库代理提供封装了数据库二进制协议的服务端版本，用于完成对异构语言的支持 shardingsphere-scaling 数据迁移相关:弹性伸缩 shardingsphere-sql-parser sql解析器：antlr4 词法语法解析出SqlStatement,提供各类数据库的方言实现。SQL 解析作为分库分表类产品的核心，其性能和兼容性是最重要的衡量指标 shardingsphere-test 测试引擎 shardingsphere-transaction 事务：整合现有的成熟事务方案，本地事务、两阶段事务（XA）和柔性事务（Seata AT 事务）提供统一的分布式事务接口 对于重点核心内容有个大致认识，后面再单独分模块分析。</description></item><item><title>分布式任务调度Hodor</title><link>https://fengzhenbing.github.io/p/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6hodor/</link><pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6hodor/</guid><description>分布式任务调度Hodor源码分析（整体结构） 简介 Hodor是一个高性能的分布式任务调度框架。
github地址(https://github.com/tincopper/hodor)
架构图 因无任何文档，以下架构图纯阅读源码个人理解后手工所画：
代码目录及分析 hodor-admin
待开发：配合前端页面做任务展示
hodor-client
客户端，用户app通过该客户端将任务信息提交到hodor-server，供其调度
集成了nettyserver服务，接收来自hodor-server的任务执行请求
hodor-client-demo
用户app示例：集成了hodor-client
hodor-common
通用库
环形队列 观察者模式（事件发布监听）模型 Excutor：多线程封装 Extension: SPI扩展方式封装 负载均衡 存储：本地缓存/mysql/h2 异常 日志 Distributor高性能队列 hodor-core
简单的spring mybatis 工程：对任务/任务执行记录等数据入库（mysql）
hodor-extension
hodor-model
实体
hodor-register
注册中心封装，目前只实现了zookeeper
hodor-register-api Hodor-register-zookeeper hodor-remoting
netty http客户端
netty http服务端
hodor-scheduler
任务定时的封装</description></item><item><title>docusaurus构建website</title><link>https://fengzhenbing.github.io/p/docusaurus%E6%9E%84%E5%BB%BAwebsite/</link><pubDate>Sun, 22 Aug 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/docusaurus%E6%9E%84%E5%BB%BAwebsite/</guid><description>docusaurus构建website 环境 Node.js version &amp;gt;= 12.13.0 以上(node -v 查看)，使用了国际化i18n，则Node.js version &amp;gt;=14以上
Yarn version &amp;gt;= 1.5 ( yarn &amp;ndash;version查看). mac下可以使用n管理node版本
Title logo等文案，首页展示 待讨论
菜单调整 Nav : 文档 社区 新闻 博客 links 国际化切换 搜索
Documentation Community News Blog Links
Footer:
首页 下载按钮 文档按钮 star按钮修改
样式修改
国际化语言 yarn write-translations --locale zh 参考https://docusaurus.io/zh-CN/docs/cli#docusaurus-write-translations-sitedir
中英文两个版本的文件名称保持一致。文档中没有指定sidebar_position时，默认按文件名称在菜单栏排序</description></item><item><title>开放平台appKey，appSecret设计</title><link>https://fengzhenbing.github.io/p/%E5%BC%80%E6%94%BE%E5%B9%B3%E5%8F%B0appkeyappsecret%E8%AE%BE%E8%AE%A1/</link><pubDate>Thu, 19 Aug 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/%E5%BC%80%E6%94%BE%E5%B9%B3%E5%8F%B0appkeyappsecret%E8%AE%BE%E8%AE%A1/</guid><description>开放平台appKey appSecret设计 1，手动注册客户端，服务端返回appKey appSecret 客户端和服务端都保存ak as 2, 客户端第一次请求 通过appKey请求token 服务端通过appKey，appSecret，时间戳，用户的必要信息生成token，可以使用JWTToken.
​ token具有有效期：Token是客户端访问服务端的凭证。
3，客户端后续请求 参数为： Token + 当前时间戳 + 参数 +签名sign1
签名sign1为 Token + 当前时间戳 + 参数+appSecret 按照一定签名算法比如 SHA256生成的签名字符串，为了保证请求中参数不被流量劫持篡改
4，服务端收到请求进行校验 时间戳校验：请求时间和当前服务端时间大于一定范围，比如5分钟，拒绝执行 Token解析：token过期拒绝执行 签名校验： 通过token解析获取到appKey，再获取到appSecret， 使用与客户端相同的签名算法SHA256得到签名sign2, 如果sign1不等于sign2，拒绝执行</description></item><item><title>Prometheus监控JVM</title><link>https://fengzhenbing.github.io/p/prometheus%E7%9B%91%E6%8E%A7jvm/</link><pubDate>Sun, 15 Aug 2021 14:16:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/prometheus%E7%9B%91%E6%8E%A7jvm/</guid><description>1. jmx_exporter 下载jmx_exporter ubuntu:/# mkdir -p /usr/local/prometheus/jmx_exporter ubuntu:/# cd /usr/local/prometheus/jmx_exporter ubuntu:/# wget https://repo1.maven.org/maven2/io/prometheus/jmx/jmx_prometheus_javaagent/0.16.1/jmx_prometheus_javaagent-0.16.1.jar 配置文件jmx_exporter jmx_exporter.yml
vim /usr/local/prometheus/jmx_exporter/jmx_exporter.yml --- rules: - pattern: &amp;quot;.*&amp;quot; java agent运行jmx_exporter 以java agent的方式启动你的一个java应用
java -javaagent:/usr/local/prometheus/jmx_prometheus_javaagent-0.16.1.jar=3010:/usr/local/prometheus/jmx_exporter.yml -jar xxx-web-0.1-SNAPSHOT.jar 2. prometheus docker方式下载运行 # docker pull prom/prometheus #下载docker镜像 # mkdir -p /etc/prometheus # vim /etc/prometheus/prometheus.yml #配置 # docker run -d \ -p 192.168.3.13:9090:9090 \ -v /etc/prometheus:/etc/prometheus \ prom/prometheus; prometheus中配置上步的jmx的metrics global:scrape_interval:15sscrape_timeout:10sevaluation_interval:15salerting:alertmanagers:- follow_redirects:truescheme:httptimeout:10sapi_version:v2static_configs:- targets:[]scrape_configs:- job_name:prometheushonor_timestamps:truescrape_interval:15sscrape_timeout:10smetrics_path:/metricsscheme:httpfollow_redirects:truestatic_configs:- targets:- 192.168.3.13:9090### 以下为jmx_exporter地址：需改为你实际的- job_name:&amp;#39;jmx&amp;#39;static_configs:scrape_interval:15s- targets:[&amp;#39;192.</description></item><item><title>mac下node升级</title><link>https://fengzhenbing.github.io/p/mac%E4%B8%8Bnode%E5%8D%87%E7%BA%A7/</link><pubDate>Wed, 21 Jul 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/mac%E4%B8%8Bnode%E5%8D%87%E7%BA%A7/</guid><description># 清除nodejs的cache sudo npm cache clean -f # 由于您可能已经拥有node，最简单的安装方式n是npm： sudo npm install -g n # node所有版本 npm view node versions # 升级到最新版本 sudo n latest # 升级到稳定版本 sudo n stable # 升级到具体版本号 sudo n xx.xx</description></item><item><title>Disruptor高性能队列</title><link>https://fengzhenbing.github.io/p/disruptor%E9%AB%98%E6%80%A7%E8%83%BD%E9%98%9F%E5%88%97/</link><pubDate>Tue, 20 Jul 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/disruptor%E9%AB%98%E6%80%A7%E8%83%BD%E9%98%9F%E5%88%97/</guid><description>Disruptor通过以下设计来解决队列速度慢的问题： 环形数组结构
元素位置定位
数组长度2^n， 位运算，加快定位的速度
无锁设计
Cas操作保证线程安全
参考 https://tech.meituan.com/2016/11/18/disruptor.html
https://blog.csdn.net/liweisnake/article/details/9113119</description></item><item><title>Envoy</title><link>https://fengzhenbing.github.io/p/envoy/</link><pubDate>Tue, 20 Jul 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/envoy/</guid><description>Envoy概述 Envoy 是以 C++ 开发的高性能代理;
其内置服务发现、负载均衡、TLS终止、HTTP/2、GRPC代理、熔断器、健康检查，基于百分比流量拆分的灰度发布、故障注入等功能
Downstream：下游主机，指连接到Envoy的主机，这些主机用来发送请求并接受响应。 Upstream：上游主机，指接收来自Envoy连接和请求的主机，并返回响应。 Listener：服务或程序的监听器， Envoy暴露一个或多个监听器监听下游主机的请求，当监听到请求时，通过Filter Chain把对请求的处理全部抽象为Filter， 例如ReadFilter、WriteFilter、HttpFilter等。 Cluster：服务提供集群，指Envoy连接的一组逻辑相同的上游主机。Envoy通过服务发现功能来发现集群内的成员，通过负载均衡功能将流量路由到集群的各个成员。 xDS：xDS中的x是一个代词，类似云计算里的XaaS可以指代IaaS、PaaS、SaaS等。DS为Discovery Service，即发现服务的意思。xDS包括CDS（cluster discovery service）、RDS（route discovery service）、EDS（endpoint discovery service）、ADS（aggregated discovery service），其中ADS称为聚合的发现服务，是对CDS、RDS、LDS、EDS服务的统一封装，解决CDS、RDS、LDS、EDS信息更新顺序依赖的问题，从而保证以一定的顺序同步各类配置信息。以上Endpoint、Cluster、Route的概念介绍如下： Endpoint：一个具体的“应用实例”，类似于Kubernetes中的一个Pod； Cluster：可以理解“应用集群”，对应提供相同服务的一个或多个Endpoint， 类似Kubernetes中Service概念，即一个Service提供多个相同服务的Pod； Route：当我们做金丝雀发布部署时，同一个服务会有多个版本，这时需要Route规则规定请求如何路由到其中的某个版本上。 http://www.dockone.io/article/9116</description></item><item><title>加密算法</title><link>https://fengzhenbing.github.io/p/%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/</link><pubDate>Mon, 21 Jun 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/</guid><description>哈希摘要算法 好的哈希摘要算法需要具备
一是易变性，这是指算法的输入端发生了任何一点细微变动，都会引发雪崩效应,使得输出端的结果产生极大的变化
常常被用来校验数据是否被篡改
二是不可逆性，摘要的过程是单向的，不可能从摘要的结果中逆向还原出输入值来
对称加密和非对称加密 对称加密 对称加密指的就是加密和解密使用同一个秘钥，所以叫做对称加密。对称加密只有一个秘钥，作为私钥。 常见的对称加密算法：DES，3DES，AES等等。
非对称加密 非对称加密指的是：加密和解密使用不同的秘钥，一把作为公开的公钥，另一把作为私钥。公钥加密的信息，只有私钥才能解密。私钥加密的信息，只有公钥才能解密。 常见的非对称加密算法：RSA，ECC
区别 对称加密算法相比非对称加密算法来说，加解密的效率要高得多。但是缺陷在于对于秘钥的管理上，以及在非安全信道中通讯时，密钥交换的安全性不能保障。所以在实际的网络环境中，会将两者混合使用.
对称加密传输大量数据
非对称加密永远对称加密的密钥协商，传输。
例如针对C/S模型，
服务端计算出一对秘钥pub/pri。将私钥保密，将公钥公开。 客户端请求服务端时，拿到服务端的公钥pub。 客户端通过AES计算出一个对称加密的秘钥X。 然后使用pub将X进行加密。 客户端将加密后的密文发送给服务端。服务端通过pri解密获得X。 然后两边的通讯内容就通过对称密钥X以对称加密算法来加解密。
三种密码学算法的对比 类型 特点 常见实现 主要用途 主要局限 哈希摘要 不可逆，即不能解密，所以并不是加密算法，只是一些场景把它当作加密算法使用。 易变性，输入发生 1 Bit 变动，就可能导致输出结果 50%的内容发生改变。 无论输入长度多少，输出长度固定（2 的 N 次幂）。 MD2/4/5/6、SHA0/1/256/512 摘要 无法解密 对称加密 加密是指加密和解密是一样的密钥。 设计难度相对较小，执行速度相对较块。 加密明文长度不受限制。 DES、AES、RC4、IDEA 加密 要解决如何把密钥安全地传递给解密者。 非对称加密 加密和解密使用的是不同的密钥。 明文长度不能超过公钥长度。 RSA、BCDSA、ElGamal 签名、传递密钥 性能与加密明文长度受限。 数字证书 解决公钥被劫持篡改的问题。由权威机构颁发保证</description></item><item><title>图解shenyu</title><link>https://fengzhenbing.github.io/p/%E5%9B%BE%E8%A7%A3shenyu/</link><pubDate>Sat, 19 Jun 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/%E5%9B%BE%E8%A7%A3shenyu/</guid><description>spi 数据同步 请求执行路径 服务调用 admin定时探活</description></item><item><title>服务链路追踪</title><link>https://fengzhenbing.github.io/p/%E6%9C%8D%E5%8A%A1%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA/</link><pubDate>Sat, 12 Jun 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/%E6%9C%8D%E5%8A%A1%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA/</guid><description>背景 随着业务的发展，系统规模也会越来越大，各微服务间的调用关系也越来越错综复杂，每一个前端请求都会形成一条复杂的分布式服务调用链路，在每条链路中任何一个依赖服务出现延迟过高或错误的时候都会引起请求最后的失败。
链路追踪原理 追踪系统根据数据收集方式的差异，可分为三种主流的实现方式，分别是基于日志的追踪（Log-Based Tracing），基于服务的追踪（Service-Based Tracing）和基于边车代理的追踪（Sidecar-Based Tracing），
实现请求跟踪 当请求发送到分布式系统的入口端点时，只需要服务跟踪框架为该请求创建一个唯一的跟踪标识Trace ID，
同时在分布式系统内部流转的时候，框架失踪保持该唯一标识，直到返回给请求方位置。
trace：服务追踪的追踪单元是从客户发起请求（request）抵达被追踪系统的边界开始，到被追踪系统向客户返回响应（response）为止的过程，称为一
个“trace”
统计各处理单元的时间延迟 当请求到达各个服务组件时，也是通过一个唯一标识Span ID来标记它的开始，具体过程以及结束。对每一个Span来说，它必须有开始和结束两个节点，通过记录开始Span和结束Span的时间戳，就能统计出该Span的时间延迟，除了时间戳记录之外，它还可以包含一些其他元数据，比如时间名称、请求信息等。
UI可视化 APM技术组件 Zipkin+Sleuth Apache SkyWalking Cat Pinpoint 特点对比</description></item><item><title>k8s Kubectl命令</title><link>https://fengzhenbing.github.io/p/k8s-kubectl%E5%91%BD%E4%BB%A4/</link><pubDate>Thu, 10 Jun 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/k8s-kubectl%E5%91%BD%E4%BB%A4/</guid><description>kubelet日志 journalctl -fu kubelet kubectl -h kubectl get namespaces kubectl get pods -A kubectl logs -f --tail=200 -l app=account -n bookstore-microservices 常用命令 #查看端口映射 kubectl get svc -n kube-system #查看 secret kubectl get secret -n kube-system #查看 token kubectl describe secret kubernetes-dashboard --namespace=kube-system #k8s 无法启动，查看日志，查找Failed journalctl -xefu kubelet #查看pod错误日志 kubectl logs kubernetes-dashboard-8556c848b7-4kpzd --namespace=kube-system #对资源进行配置 kubectl apply -f kubernetes-dashboard.yaml kubectl delete -f kubernetes-dashboard.ya YAML配置文件管理对象 对象管理： # 创建deployment资源 kubectl create -f nginx-deployment.yaml # 查看deployment kubectl get deploy # 查看ReplicaSet kubectl get rs # 查看pods所有标签 kubectl get pods --show-labels # 根据标签查看pods kubectl get pods -l app=nginx # 滚动更新镜像 kubectl set image deployment/nginx-deployment nginx=nginx:1.</description></item><item><title>架构演变</title><link>https://fengzhenbing.github.io/p/%E6%9E%B6%E6%9E%84%E6%BC%94%E5%8F%98/</link><pubDate>Thu, 10 Jun 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/%E6%9E%B6%E6%9E%84%E6%BC%94%E5%8F%98/</guid><description>单体架构(spring boot) 优点：所有代码都运行在同一个进程空间之内，所有模块、方法的调用都无须考虑网络分区、对象复制这些麻烦的事和性能损失。
缺点：损失了各个功能模块的自治、隔离能力；
​ 由于隔离能力的缺失难以阻断错误传播、不便于动态更新程序以外，还面临难以技术异构的困难
​ 可以 使用OSGi 这种运行时模块化框架，但是太复杂了。
SOA 架构（Service-Oriented Architecture） 面向服务的架构是一次具体地、系统性地成功解决分布式服务主要问题的架构模式。
SOAP 协议被逐渐边缘化的本质原因：过于严格的规范定义带来过度的复杂性。而构建在 SOAP 基础之上的 ESB、BPM、SCA、SDO 等诸多上层建筑，进一步加剧了这种复杂性。
微服务架构(spring cloud) 微服务是一种软件开发技术，是一种 SOA 的变体形式。
升级背景：
制约软件质量与业务能力提升的最大因素是人而非硬件： 单体架构没有什么有效阻断错误传播的手段 技术异构的需求从可选渐渐成为必须：很多 Java 不擅长的事情 人工智能python 分布式协调工具 Etcd ,NSI C 编写的 Redis， &amp;hellip; 由于隔离能力的缺失，单体除了难以阻断错误传播、不便于动态更新程序以外，还面临难以技术异构的困难，每个模块的代码都通常需要使用一样的程序语言，乃至一样的编程框架去开发。
随着软件架构演进，构筑可靠系统从“追求尽量不出错”，到正视“出错是必然”的观念转变，才是微服务架构得以挑战并逐步开始取代运作了数十年的单体架构的底气所在
微服务时代充满着自由的气息，微服务时代充斥着迷茫的选择。
微服务架构(Kubernetes) 升级背景：
微服务中的各种新技术名词，如配置中心、服务发现、网关、熔断、负载均衡等等带来的技术组件 Config、Eureka、Zuul、Hystrix、Ribbon、Feign 等
占据了产品的大部分编译后的代码容量
之前在应用层面而不是基础设施层面去解决这些分布式问题，完全是因为由硬件构成的基础设施，跟不上由软件构成的应用服务的灵活性的无奈之举
以 Docker Swarm、Apache Mesos 与 Kubernetes 为主要竞争者的“容器战争”终于有了明确的结果，Kubernetes 登基加冕
容器动态构建出 DNS 服务器、服务负载均衡器等一系列虚拟化的基础设施，去代替原有的应用层面的技术组件</description></item><item><title>Kubeadm安装Kubernetes</title><link>https://fengzhenbing.github.io/p/kubeadm%E5%AE%89%E8%A3%85kubernetes/</link><pubDate>Tue, 08 Jun 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/kubeadm%E5%AE%89%E8%A3%85kubernetes/</guid><description>1.环境准备 安装 Kubernetes 最小需要 2 核处理器、2 GB 内存，且为 x86 架构（暂不支持 ARM 架构)
本次实验操作系统：ubantu 20.04LTS
Kubernetes 并不在主流 Debian 系统自带的软件源中，所以要手工注册，然后才能使用apt-get安装
# 添加GPG Key $ sudo curl -fsSL https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - # 添加K8S软件源 $ sudo add-apt-repository &amp;#34;deb https://apt.kubernetes.io/ kubernetes-xenial main&amp;#34; 如果不能科学上网，可以使用阿里云的软件源地址
# 添加GPG Key $ curl -fsSL http://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo apt-key add - # 添加K8S软件源 $ sudo add-apt-repository &amp;#34;deb http://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial main&amp;#34; 添加源后需要更新
sudo apt-get update 2. 安装 kubelet、kubectl、kubeadm 官网介绍：https://kubernetes.io/docs/reference/setup-tools/kubeadm/</description></item><item><title>优雅停机</title><link>https://fengzhenbing.github.io/p/%E4%BC%98%E9%9B%85%E5%81%9C%E6%9C%BA/</link><pubDate>Wed, 19 May 2021 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/%E4%BC%98%E9%9B%85%E5%81%9C%E6%9C%BA/</guid><description>1, ShutdownHook初识 在Java程序中可以通过添加关闭钩子，实现在程序退出时关闭资源、平滑退出的功能。 并且在以下几种场景将调用该钩子
程序正常退出 使用System.exit() 终端使用Ctrl+C触发的中断 系统关闭 使用Kill pid命令干掉进程 具体来讲Runtime.addShutdownHook 添加钩子到 ApplicationShutdownHooks中。
// Runtime添加钩子（钩子具体来讲就是一个要执行的线程任务） public void addShutdownHook(Thread hook) { SecurityManager sm = System.getSecurityManager(); if (sm != null) { sm.checkPermission(new RuntimePermission(&amp;#34;shutdownHooks&amp;#34;)); } ApplicationShutdownHooks.add(hook); } // Runtime去除钩子 public boolean removeShutdownHook(Thread hook) { SecurityManager sm = System.getSecurityManager(); if (sm != null) { sm.checkPermission(new RuntimePermission(&amp;#34;shutdownHooks&amp;#34;)); } return ApplicationShutdownHooks.remove(hook); } 再看ApplicationShutdownHooks
class ApplicationShutdownHooks { /* The set of registered hooks */ private static IdentityHashMap&amp;lt;Thread, Thread&amp;gt; hooks; static { try { Shutdown.</description></item><item><title>jvm垃圾回收</title><link>https://fengzhenbing.github.io/p/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/</link><pubDate>Sun, 14 Mar 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/</guid><description>jvm垃圾回收 对象存活判断算法 引用计数算法 问题： 可能存在两个对象相互引用，导致无法回收，内存泄漏
根可达算法 维护引用的链表； 如果某个对象无法到达根节点，说明可以被回收
那么哪些对象是根对象呢？主要包含：JVM stack，native method stack，run-time constant pool(运行常量池里的对象)，static references in method area(方法区里的静态引用)，Clazz等。
垃圾回收算法 对停顿时间(延时)和吞吐量的权衡，没有最好，只有最适合当前业务场景的回收方式
针对 堆内存回收；
方法区
java 8 前 永久区（也参与垃圾回收，一样的算法，省事了，但是有默认最大内存限制，容易oom） java 8 彻底抛弃了 永久区，叫元数据区，使用本地内存 分代收集理论 新生代
老年代
跨代引用： Remember set
标记清除 产生内存碎片，内存分配复杂了。 可能需要类似硬盘的 “分区空闲分配链表” 等复杂方式解决
Cms搜集器在old 区回收时采用， 但是内存碎片达到一定量，会采取一次标记整理。（和稀泥的做法，结合两者，）
标记复制 一般用于新生代回收: Serial ParNew 的新生代采用该算法
scurvivorRadio Ēden survivor survivor 8:1:1
对象存活率较高时，需要更多的复制操作，效率会降低
标记整理 用于old区：
相对于 标记清除， 标记后，需要移动：将存活的对象移动到内存区域的一端。</description></item><item><title>pulsar</title><link>https://fengzhenbing.github.io/p/pulsar/</link><pubDate>Tue, 23 Feb 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/pulsar/</guid><description>相关概念 计算存储分离 安装测试 # 下载 wget https://mirrors.bfsu.edu.cn/apache/pulsar/pulsar-2.7.1/apache-pulsar-2.7.1-bin.tar.gz tar xvfz apache-pulsar-2.7.1-bin.tar.gz cd apache-pulsar-2.7.1 # 单机启动 bin/pulsar standalone # 消费消息 bin/pulsar-client consume my-topic -s &amp;#34;first-subscription&amp;#34; # 生产消息 bin/pulsar-client produce my-topic --messages &amp;#34;hello-pulsar&amp;#34; 相关资料 官网快速启动</description></item><item><title>rocketMQ</title><link>https://fengzhenbing.github.io/p/rocketmq/</link><pubDate>Sat, 20 Feb 2021 09:16:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/rocketmq/</guid><description>相关概念 二代mq, 纯java开发，和kafka无本质区别
安装测试 # 下载 4.8.0 wget https://downloads.apache.org/rocketmq/4.8.0/rocketmq-all-4.8.0-bin-release.zip unzip rocketmq-all-4.8.0-bin-release.zip #运行命名服务， 替代kafka的zk nohup sh bin/mqnamesrv &amp;amp; #查看日志 tail -f ~/logs/rocketmqlogs/namesrv.log #运行broker nohup sh bin/mqbroker -n localhost:9876 &amp;amp; #查看日志 tail -f ~/logs/rocketmqlogs/broker.log # 发送消息 export NAMESRV_ADDR=localhost:9876 sh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer #消费消息 sh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer 相关资料 官网快速开始
中文文档</description></item><item><title>rabbitMQ</title><link>https://fengzhenbing.github.io/p/rabbitmq/</link><pubDate>Fri, 19 Feb 2021 10:16:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/rabbitmq/</guid><description>Rabbitmq相关概念 一代mq，erlang开发， 改进activemq
Publisher 消息生产者, 返送消息时指定exchange 和routing key, 即可以将消息路由到匹配的queue中 Routing key Binding 通过routing key 将queue和exchange绑定 Exchange 工具人。。交易所。。代理 FanoutExchange: 将消息分发到所有的绑定队列，无routingkey的概念，发送时不指定routing key HeadersExchange ：通过添加属性key-value匹配 DirectExchange: 按照routingkey分发到指定队列 TopicExchange:多关键字匹配 正则 Consumer 1. Exchange概念
Exchange：接收消息，并根据路由键转发消息所绑定的队列。 蓝色框：客户端发送消息至交换机，通过路由键路由至指定的队列。 黄色框：交换机和队列通过路由键有一个绑定的关系。 绿色框：消费端通过监听队列来接收消息。
Docker方式安装运行 docker pull rabbitmq:management docker run -itd --name rabbitmq-test -e RABBITMQ_DEFAULT_USER=admin -e RABBITMQ_DEFAULT_PASS=admin -p 15672:15672 -p 5672:5672 rabbitmq:management docker exec -it rabbitmq-test /bin/bash 高可用
镜像集群模式（高可用性） 这种模式，才是所谓的 RabbitMQ 的高可用模式。跟普通集群模式不一样的是，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。</description></item><item><title>康威定律</title><link>https://fengzhenbing.github.io/p/%E5%BA%B7%E5%A8%81%E5%AE%9A%E5%BE%8B/</link><pubDate>Wed, 13 Jan 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/%E5%BA%B7%E5%A8%81%E5%AE%9A%E5%BE%8B/</guid><description>康威定律：组织决定产品形态 第一定律 组织设计的产品/设计等价于这个组织的沟通结构。
第二定律 时间再多一件事情也不可能做的完美，但总有时间做完一件事情
第三定律 线型系统和线型组织架构间有潜在的异质同态特性
第四定律 大的系统组织总是比小系统更倾向于分解</description></item><item><title>Synchronized锁</title><link>https://fengzhenbing.github.io/p/synchronized%E9%94%81/</link><pubDate>Tue, 15 Dec 2020 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/synchronized%E9%94%81/</guid><description>Synchronized Object.wait()：释放当前对象锁，并进入阻塞队列(wait set) Object.notify()：唤醒当前对象阻塞队列(wait set)里的任一线程（并不保证唤醒哪一个） Object.notifyAll()：唤醒当前对象阻塞队列(wait set)里的所有线程, 进到entry set 去竞争锁 为什么wait,notify和notifyAll要与synchronized一起使用？ Wait 只有通过synchronized拿到锁，才能进入wait set
notify notifyAll只有通过synchronized拿到锁，才能去唤醒 wait set 里线程 到entry set
object monitor 对象在内存中的存储 Markword 32位jvm 结构如下： 重量级锁即为 Synchronized 的锁
锁升级 参考 https://mp.weixin.qq.com/s/2yxexZUr5MWdMZ02GCSwdA</description></item><item><title>hazelcast</title><link>https://fengzhenbing.github.io/p/hazelcast/</link><pubDate>Mon, 14 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/hazelcast/</guid><description>安装 docker docker pull hazelcast/hazelcast docker run -e HZ_NETWORK_PUBLICADDRESS=192.168.3.14:5701 -p 5701:5701 hazelcast/hazelcast:$HAZELCAST_VERSION docker run -e HZ_NETWORK_PUBLICADDRESS=192.168.3.14:5702 -p 5702:5701 hazelcast/hazelcast:$HAZELCAST_VERSION docker run -p 8080:8080 hazelcast/management-center</description></item><item><title>redis应用场景</title><link>https://fengzhenbing.github.io/p/redis%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/</link><pubDate>Sun, 13 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/redis%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/</guid><description>一.业务数据缓存* 经典用法。
通用数据缓存，string，int，list，map等。
验证码等 实时热数据，最新500条数据。
如热搜新闻。。 会话缓存，token缓存等。
spring-session-data-redis sesion共享 二.业务数据处理 非严格一致性要求的数据
评论，点击，点赞等。
set key 0 incr key // incr readcount::{帖子id} 每阅读一次 get key // get readcount::{帖子id} 获取阅读量 业务数据去重
订单处理的幂等校验等。 如订单id放到redis 的set中去重复， bitmap 等 业务数据排序
排名，排行榜等。 使用sortedset 三.全局一致计数 * 全局流控计数</description></item><item><title>01.gateway整体逻辑</title><link>https://fengzhenbing.github.io/p/01.gateway%E6%95%B4%E4%BD%93%E9%80%BB%E8%BE%91/</link><pubDate>Thu, 10 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/01.gateway%E6%95%B4%E4%BD%93%E9%80%BB%E8%BE%91/</guid><description>gateway整体逻辑 1.流程图 2.几个关键的类 org.springframework.web.reactive.DispatcherHandler: 请求分发处理器； Spring WebFlux 的访问入口； 类似于spring mvc DispatcherServlet,可以类比spring mvc 接收到请求; DispatcherHandler匹配 HandlerMapping此处会匹配到scg的RoutePredicateHandlerMapping org.springframework.cloud.gateway.handler.RoutePredicateHandlerMapping：HandlerMapping的实现；
通过RouteLocator匹配 Route: getHandlerInternal方法调用lookupRoute()方法，通过routeLocator获取所有配置的route,通过里面的Predicate配置来遍历判断找出符合的Route getHandlerInternal中返回FilteringWebHandler org.springframework.cloud.gateway.handler.FilteringWebHandler: WebHandler的实现；
FilteringWebHandler被RoutePredicateHandlerMapping返回后，在DispatcherHandler中被SimpleHandlerAdapter执行handle方法； 责任链模式：获取Route的GatewayFilter数组，创建DefaultGatewayFilterChain的过滤链；链式调用GatewayFilter 3.项目结构 核心module为spring-cloud-gateway-server
actuate: 实现springboot actuator的端点，暴露route filter predicate等信息 config: 使用springboot的配置注解的各类配置类 discover：通过注册中心获取路由Route的核心功能配置类及实现类 event：实现ApplicationEvent的事件类，例如路由刷新事件RefreshRoutesEvent filter: 包含特定路由的GatewayFilterFactory，GatewayFiler以及全局的GlobalFilter handler: 包含匹配route的断言工厂AbstractRoutePredicateFactory的所有默认实现，以及核心类FilteringWebHandler及RoutePredicateHandlerMapping route：路由的定义类，及路由定位类CachingRouteLocator的所有实现，及路由定义定位类CompositeRouteDefinitionLocator的所有实现，路由存储接口RouteDefinitionRepository及其所有实现 support：工具类；如HTTP协议处理，组件名处理，日期转换等</description></item><item><title>02.reactor响应式编程学习</title><link>https://fengzhenbing.github.io/p/02.reactor%E5%93%8D%E5%BA%94%E5%BC%8F%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0/</link><pubDate>Thu, 10 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/02.reactor%E5%93%8D%E5%BA%94%E5%BC%8F%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0/</guid><description>reactor 使用 ![image (1)](https://fengzhenbing.github.io/img/picgo/image (1).png)
Webflux 模块的名称是 spring-webflux，名称中的 Flux 来源于 Reactor 中的类 Flux。 Reactor 两个核心概念做一些澄清，一个是Mono，另一个是Flux
Flux ：表示的是包含 0 到 N 个元素的异步序列。包含三个类型 正常的包含元素的消息 序列结束的消息 序列出错的消息 Mono： 表示的是包含 0 或者 1 个元素的异步序列。该序列中同样可以包含与 Flux 相同的三种类型的消息通知。 示例代码： https://github.com/fengzhenbing/spring-cloud-gateway-demo/blob/master/demo-gateway/src/main/java/org/fzb/demo/gateway/RectorController.java</description></item><item><title>03.scg NettyWebServer启动过程</title><link>https://fengzhenbing.github.io/p/03.scg-nettywebserver%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B/</link><pubDate>Thu, 10 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/03.scg-nettywebserver%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B/</guid><description>scg NettyWebServer启动过程 spring cloud gateway(下面简称scg)依赖spring webflux, 而spring webflux依赖于reactor-netty,也就是scg启动过程中最终会启动netty做为服务器。 springboot中定义一下几种服务器：
1 启动ReactiveWebServerApplicationContext 从springboot启动开始分析
SpringApplication.run(GatewayApplication.class, args); 设置webApplicationType的值：REACTIVE还是servlet的。
public SpringApplication(ResourceLoader resourceLoader, Class&amp;lt;?&amp;gt;... primarySources) { this.resourceLoader = resourceLoader; Assert.notNull(primarySources, &amp;#34;PrimarySources must not be null&amp;#34;); this.primarySources = new LinkedHashSet&amp;lt;&amp;gt;(Arrays.asList(primarySources)); this.webApplicationType = WebApplicationType.deduceFromClasspath();//fzb 通过类路径中类，推测web应用类型：REACTIVE还是servlet的。 setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass(); } 再看deduceFromClasspath方法：判断DispatcherHandler存在还是DispatcherServlet存在
static WebApplicationType deduceFromClasspath() {//fzb 判断DispatcherHandler存在还是DispatcherServlet存在 if (ClassUtils.isPresent(WEBFLUX_INDICATOR_CLASS, null) &amp;amp;&amp;amp; !ClassUtils.isPresent(WEBMVC_INDICATOR_CLASS, null) &amp;amp;&amp;amp; !ClassUtils.isPresent(JERSEY_INDICATOR_CLASS, null)) { return WebApplicationType.REACTIVE; } for (String className : SERVLET_INDICATOR_CLASSES) { if (!</description></item><item><title>04.scg 一次请求的执行过程</title><link>https://fengzhenbing.github.io/p/04.scg-%E4%B8%80%E6%AC%A1%E8%AF%B7%E6%B1%82%E7%9A%84%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/</link><pubDate>Thu, 10 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/04.scg-%E4%B8%80%E6%AC%A1%E8%AF%B7%E6%B1%82%E7%9A%84%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/</guid><description>一次请求的执行过程</description></item><item><title>05.route路由的配置加载</title><link>https://fengzhenbing.github.io/p/05.route%E8%B7%AF%E7%94%B1%E7%9A%84%E9%85%8D%E7%BD%AE%E5%8A%A0%E8%BD%BD/</link><pubDate>Thu, 10 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/05.route%E8%B7%AF%E7%94%B1%E7%9A%84%E9%85%8D%E7%BD%AE%E5%8A%A0%E8%BD%BD/</guid><description>route路由的配置加载 主要在sprng-cloud-gateway-server的route包定义路由相关的定义，构建和加载
![路由](https://fengzhenbing.github.io/img/picgo/image (2).png)
0.相关配置 通过springboot spi方式，springboot会启动spring.factories中配置的 org.springframework.cloud.gateway.discovery.GatewayDiscoveryClientAutoConfiguration org.springframework.boot.autoconfigure.EnableAutoConfiguration=\ org.springframework.cloud.gateway.config.GatewayAutoConfiguration,\ org.springframework.cloud.gateway.discovery.GatewayDiscoveryClientAutoConfiguration,\ ... 1.路由定义 路由定义RouteDefinition public class RouteDefinition { private String id; @NotEmpty @Valid//fzb 断言定义数组 private List&amp;lt;PredicateDefinition&amp;gt; predicates = new ArrayList&amp;lt;&amp;gt;(); @Valid//fzb 过滤器定义数组 private List&amp;lt;FilterDefinition&amp;gt; filters = new ArrayList&amp;lt;&amp;gt;(); @NotNull//fzb 路由路径 private URI uri; ... } 路由定义定位器 获取路由的定义，负责读取上述路由定义配置 RouteDefinition，最终会通过路由定义生成路由
public interface RouteDefinitionLocator { //fzb 获取路由定义对象 Flux&amp;lt;RouteDefinition&amp;gt; getRouteDefinitions(); } 有以下实现：
![image (3)](https://fengzhenbing.</description></item><item><title>06.route通过注册中心自动配置加载</title><link>https://fengzhenbing.github.io/p/06.route%E9%80%9A%E8%BF%87%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E8%87%AA%E5%8A%A8%E9%85%8D%E7%BD%AE%E5%8A%A0%E8%BD%BD/</link><pubDate>Thu, 10 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/06.route%E9%80%9A%E8%BF%87%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E8%87%AA%E5%8A%A8%E9%85%8D%E7%BD%AE%E5%8A%A0%E8%BD%BD/</guid><description>route通过注册中心Eureka自动加载配置 配置 gateway及后端微服务引入注册中心客户端eureka-client &amp;lt;!-- 引入 Spring Cloud Netflix Eureka Client 相关依赖，将 Eureka 作为注册中心的客户端，并实现对其的自动配置 --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-cloud-starter-netflix-eureka-client&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; eureka-client starter的引入，会同时引入ribbon,作为后续请求，负载均衡的实现 spring.cloud.gateway.discovery.locator.enabled设为true,启用服务发现的DiscoveryClientRouteDefinitionLocator
spring:cloud:# Spring Cloud Gateway 配置项，对应 GatewayProperties 类gateway:discovery:locator:enabled:true# default fase，设为true开启@Configuration(proxyBeanMethods = false) @ConditionalOnProperty(value = &amp;#34;spring.cloud.discovery.reactive.enabled&amp;#34;,//fzb 默认使用响应式的方式 matchIfMissing = true) public static class ReactiveDiscoveryClientRouteDefinitionLocatorConfiguration { @Bean//fzb spring.cloud.gateway.discovery.locator.enabled配为true时，才开启DiscoveryClientRouteDefinitionLocator @ConditionalOnProperty(name = &amp;#34;spring.cloud.gateway.discovery.locator.enabled&amp;#34;) public DiscoveryClientRouteDefinitionLocator discoveryClientRouteDefinitionLocator( ReactiveDiscoveryClient discoveryClient,//响应式的客服端 Eureka就是 EurekaReactiveDiscoveryClient DiscoveryLocatorProperties properties) { return new DiscoveryClientRouteDefinitionLocator(discoveryClient, properties); } } eureka-client的引入，会开启TimedSupervisorTask执行HeartbeatThread的心跳任务， 默认每隔30s一次 RouteRefreshListener 每隔30s接收到HeartBeatEvent事件，同时会发送RefreshRoutes事件</description></item><item><title>07.precidate的对路由进行选择</title><link>https://fengzhenbing.github.io/p/07.precidate%E7%9A%84%E5%AF%B9%E8%B7%AF%E7%94%B1%E8%BF%9B%E8%A1%8C%E9%80%89%E6%8B%A9/</link><pubDate>Thu, 10 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/07.precidate%E7%9A%84%E5%AF%B9%E8%B7%AF%E7%94%B1%E8%BF%9B%E8%A1%8C%E9%80%89%E6%8B%A9/</guid><description>precidate选择路由</description></item><item><title>08.filter的配置加载及合并</title><link>https://fengzhenbing.github.io/p/08.filter%E7%9A%84%E9%85%8D%E7%BD%AE%E5%8A%A0%E8%BD%BD%E5%8F%8A%E5%90%88%E5%B9%B6/</link><pubDate>Thu, 10 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/08.filter%E7%9A%84%E9%85%8D%E7%BD%AE%E5%8A%A0%E8%BD%BD%E5%8F%8A%E5%90%88%E5%B9%B6/</guid><description/></item><item><title>soul整体结构</title><link>https://fengzhenbing.github.io/p/soul%E6%95%B4%E4%BD%93%E7%BB%93%E6%9E%84/</link><pubDate>Thu, 10 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/soul%E6%95%B4%E4%BD%93%E7%BB%93%E6%9E%84/</guid><description>ShenYu介绍 官网
高性能，多协议，易扩展，响应式的API Gateway 丰富的协议 支持 dubbo ，tars， springcloud grpc。 插件化 插件化设计思想，插件热插拔，易扩展。 流控 灵活的流量筛选，能满足各种流量控制。 内置插件 内置丰富的插件支持，鉴权，限流，熔断，防火墙等。 高性能 流量配置动态化，性能极高，网关消耗在 1~2ms。 集群部署 支持集群部署，支持 A/B Test，蓝绿发布。 soul项目结构 soul-admin
soul网关管理端，配合soul-dashbord
Soul-bootstrap
网关启动工程： 实际引入soul-spring-boot-starter-gateway(soul-web)
Soul-client
为下游服务提供者提供各类服务接入网关soul的客户端
Soul-client-common Soul-client-dubbo Soul-client-grpc Soul-client-http Soul-client-sofa Soul-client-tars Soul-common
Soul-dashbord</description></item><item><title>安装redis</title><link>https://fengzhenbing.github.io/p/%E5%AE%89%E8%A3%85redis/</link><pubDate>Thu, 10 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/%E5%AE%89%E8%A3%85redis/</guid><description>下载 https://redis.io/download
编译 wget https://download.redis.io/releases/redis-6.0.10.tar.gz tar xzf redis-6.0.10.tar.gz cd redis-6.0.10 sudo make 运行 #复制配置文件及命令 mkdir ./bin mkdir ./conf sudo cp ./src/mkreleasehdr.sh ./bin sudo cp ./src/redis-benchmark ./bin sudo cp ./src/redis-check-rdb ./bin sudo cp ./src/redis-cli ./bin sudo cp ./src/redis-server ./bin sudo cp ./redis.conf ./conf #运行 ./bin/redis-server ./conf/redis.conf 配置 redis.conf
#修改为守护模式 daemonize yes #设置进程锁文件 pidfile /usr/local/redis-4.0.11/redis.pid #端口 port 6379 #客户端超时时间 timeout 300 #日志级别 loglevel debug #日志文件位置 logfile /usr/local/redis-4.0.11/log-redis.log #设置数据库的数量，默认数据库为0，可以使用SELECT &amp;lt;dbid&amp;gt;命令在连接上指定数据库id databases 16 ##指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合 #save &amp;lt;seconds&amp;gt; &amp;lt;changes&amp;gt; #Redis默认配置文件中提供了三个条件： save 900 1 save 300 10 save 60 10000 #指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间， #可以关闭该#选项，但会导致数据库文件变的巨大 rdbcompression yes #指定本地数据库文件名 dbfilename dump.</description></item><item><title>Hugo搭建博客</title><link>https://fengzhenbing.github.io/p/hugo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/</link><pubDate>Tue, 08 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/hugo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/</guid><description>通过Hugo搭建静态博客网站，再通过github pages部署运行
Hugo介绍 Hugo是一种用Go语言编写的快速，现代的静态网站生成器，旨在让网站创建再次变得有趣。 性能高，安全性和易用性是主要特点 拥有超快的速度，强大的内容管理和强大的模板语言，使其非常适合各种静态网站。 Hugo安装 # mac上安装 brew install hugo # windows可通过Chocolatey上安装 choco install hugo -confirm # 版本验证 hugo version hugo主题 查找你喜欢的主题 在此我选择的主题为toha 详情 初始化网站模板 # 首先在github下创建xxx.github.io的仓库 git clone https://github.com/fengzhenbing/fengzhenbing.github.io.git cd ./fengzhenbing.github.io # 初始化模板 hugo new site ./ -f=yaml --force #添加hugo-toha主题 git submodule add https://github.com/hugo-toha/toha.git themes/toha #本地运行 hugo server -t toha -w 修改配置 参考themes/toha/exampleSite，配置网站根目录下的config.yml文件，配置网站各个模块
baseURL:https://fengzhenbing.github.io/languageCode:en-usdefaultContentLanguage:cntitle:&amp;#34;Feng Zhenbing&amp;#39;s Blog&amp;#34;theme:&amp;#34;toha&amp;#34;# Manage languages# For any more details, you can check the official documentation: https://gohugo.</description></item><item><title>配置中心刷新</title><link>https://fengzhenbing.github.io/p/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E5%88%B7%E6%96%B0/</link><pubDate>Tue, 08 Dec 2020 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E5%88%B7%E6%96%B0/</guid><description>配置中心刷新原理 nacos和spring cloud config两种配置中心动态刷新的范围都是以下两种：
@ConfigurationProperties 注解的配置类 @RefreshScope 注解的bean 手动刷新 post请求config客户端的/refresh端点
自动刷新 WebHooks动态触发刷新
spring-cloud-bus动态刷新
这时Spring Cloud Bus做配置更新步骤如下:
提交代码触发post给Server端发送bus/refresh Server端接收到请求并发送给Spring Cloud Bus Spring Cloud bus接到消息并通知给其它客户端 其它客户端接收到通知，请求Server端获取最新配置 全部客户端均获取到最新的配置 这样的话我们在server端的代码做一些改动，来支持/actuator/bus-refresh
Spring Cloud Bus Spring Cloud Bus 使用轻量级的消息代理来连接微服务架构中的各个服务，可以将其用于广播状态更改（例如配置中心配置更改）或其他管理指令
目前 Spring Cloud Bus 支持两种消息代理：RabbitMQ 和 Kafka。
参考
https://blog.csdn.net/woshilijiuyi/article/details/88293782
https://www.cnblogs.com/babycomeon/p/11141160.html</description></item><item><title>小程序框架</title><link>https://fengzhenbing.github.io/p/%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%A1%86%E6%9E%B6/</link><pubDate>Mon, 23 Nov 2020 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%A1%86%E6%9E%B6/</guid><description>小程序原理 使用两个线程：保证平台安全性，不能让开发者控制 render 线程，控制 render 线程将会造成小程序平台方管控困难 worker线程： 用户控制 响应 render 线程的事件，并执行小程序业务逻辑。 准备好数据，通过 setData 传到 page 中，由 page 进行渲染。 render线程：接收数据渲染到页面 TARO 官网
https://taro-ui.jd.com/
特点
编译时转换
React vue &amp;hellip;
一套组件可以在 微信小程序，支付宝小程序，百度小程序，H5 多端适配运行
创建项目
# 使用 npm 安装 CLI $ npm install -g @tarojs/cli # OR 使用 yarn 安装 CLI $ yarn global add @tarojs/cli # OR 安装了 cnpm，使用 cnpm 安装 CLI $ cnpm install -g @tarojs/cli Remax 官网</description></item><item><title>kafka基础</title><link>https://fengzhenbing.github.io/p/kafka%E5%9F%BA%E7%A1%80/</link><pubDate>Tue, 20 Oct 2020 14:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/kafka%E5%9F%BA%E7%A1%80/</guid><description>kafka相关概念 二代mq, scala开发
broker
Kafka 集群包含一个或多个服务器，这种服务器被称为 broker。
topic
每条发布到 Kafka 集群的消息都有一个类别，这个类别被称为 Topic。 (物理上不同 Topic 的消息分开存储，逻辑上一个 Topic 的消息虽然保存于一个或 多个 broker 上，但用户只需指定消息的 Topic 即可生产或消费数据而不必关心数 据存于何处)。
patition
Partition 是物理上的概念，每个 Topic 包含一个或多个 Partition。
消息会根据 分区策略 追加到分区文件的末尾，属于顺序写磁盘，因此效率非常高（经验证，顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）。
producer
负责发布消息到 Kafka broker。
customer
消息消费者，向 Kafka broker 读取消息的客户端
Customer group
consumer group是kafka提供的可扩展且具有容错性的消费者机制。既然是一个组，那么组内必然可以有多个消费者或消费者实例(consumer instance)，它们共享一个公共的ID，即group ID。组内的所有消费者协调在一起来消费订阅主题(subscribed topics)的所有分区(partition)。当然，每个分区只能由同一个消费组内的一个consumer来消费。
特点：
consumer group下可以有一个或多个consumer instance，consumer instance可以是一个进程，也可以是一个线程 group.id是一个字符串，唯一标识一个consumer group consumer group下订阅的topic下的每个分区只能分配给某个group下的一个consumer(当然该分区还可以被分配给其他group) leader</description></item><item><title>消息基础</title><link>https://fengzhenbing.github.io/p/%E6%B6%88%E6%81%AF%E5%9F%BA%E7%A1%80/</link><pubDate>Sun, 11 Oct 2020 09:16:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/%E6%B6%88%E6%81%AF%E5%9F%BA%E7%A1%80/</guid><description>消息队列作用 异步通信：异步通信，减少线程等待，特别是处理批量等大事务、耗时操作。 系统解耦:系统不直接调用，降低依赖，特别是不在线也能保持通信最终完成。 削峰填谷:压力大的时候，缓冲部分请求消息，类似于背压处理。 可靠通信:提供多种消息模式、服务质量、顺序保障等。 消息处理模式 点对点： PTP =&amp;gt; queue 发布订阅： PubSub =&amp;gt; Topic 消息语义 QOS At most once At least once Exactly once *支持数据不丢失的ack机制*</description></item><item><title>innodb概述及原理</title><link>https://fengzhenbing.github.io/p/innodb%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86/</link><pubDate>Sat, 12 Sep 2020 14:16:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/innodb%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%8E%9F%E7%90%86/</guid><description>Innodb概述 该存储引擎是第一个完整支持ACID事 务的MySOL存储引擎，其特点是行锁设计、支持MVCC、支持外键、提供一致性非锁定读，同时被设计用来最有效地利用以及使用内存和CPU；
体系结构如下：
InnoDB存储引擎有多个内存块，这些内存块组成一个内存池，主要负责如下工作：
维护所有进程、线程需要访问的多个内部数据结构 缓存磁盘上的数据，方便快速读取，同时在对磁盘文件的数据修改之前在这里缓存 重做日志（redo log）缓冲 后台线程的主要作用：
负责刷新内存池中的数据，保证缓冲池中的内存缓存的是最近的数据
将已修改的数据文件刷新到磁盘文件
innodb 内存结构 缓冲池 InnoDB存储引擎是基于磁盘存储的，并将其中的记录按照页的方式进行管理。因此 可将其视为基于磁盘的数据库系统 (Disk-baseDatabase)。在数据库系统中，由于CPU 速度与磁盘速度之间的鸿沟，基于磁盘的数据库系统通常使用缇冲池技术来提高数据库 的整体性能 .
缓冲池简单来说就是一块内存区域，通过内存的速度来弥补磁盘速度较慢对数据库性能的影响。在数据库中进行读取页的操作，首先将从磁盘读到的页存放在缓冲他中 这个过程称为将页“FIX”在缓冲池中。下一次再读相同的页时，首先判断该页是否在 缓冲他中，若在缓冲池中，称该页在缓冲池中被命中，直接读取该页。否则，读取磁盘 上的页 .
对于数据库中页的修改操作，则首先修改在缓冲池中的页，然后再以一定的频率刷 新到磁盘上，这里需要注意的是，页从缓冲池剧新回磁盘的操作并不是在每次页发生更新时触发，而是通过一种称为Checkpoint的机制刷新, 提高据库的整体性能
综上所述，缓冲池的大小 直接影响着数据库的整体性能。
SHOWVARIABLESLIKE&amp;#39;innodb_buffer_poo1_size&amp;#39;\G;缓冲池管理 LRU Free Flush LRU list 通常来说 数据库中的缓冲池是通过LRU (Latest Recent Used， 最近最少使用》 算法来进行管理的, 即最频繁使用的页(一页16k)在LRU列表的前端，而最少使用的页在 LRU列表的尾端, 当缓冲池不能存放新读取到的页时 将首先释放LRU列表中尾 端的页.
Buffer Pool的LRU算法与普通的LRU算法不一样，新数据页插入时并不从头部插入，而是从中间位置插入（默认配置下，该位置从表头计算为列表5/8的位置)，在该位置，列表被分成了如下两个子列表：
在头部是最近被访问的新页列表 在尾部是很少被访问的旧页列表 可以和jvm的young区 old区类比。
为什么这么设计？？ 直接将读取的页放人到LRU列表的首部呢?这是因为若直接将读取到的页放人到LRU的首部，那么某些SQL操作可能会使缓冲池中 的页被刷新出，从而影响缓冲池的效率。常见的这类操作为索引或数据的扫描操作。这 类操作需要访问表中的许多页，甚至是全部的页，而这些页通常来说又仅在这次查询操 作中需要，并不是活跃的热点数据。如果页被放人LRU列表的首部，那么非常可能将 所需要的热点数据页从LRU列表中移除，而在下一次需要读取该页时， InnoDB存储引 肇需要再次访问磁盘</description></item><item><title>数据库日志总结</title><link>https://fengzhenbing.github.io/p/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%97%A5%E5%BF%97%E6%80%BB%E7%BB%93/</link><pubDate>Sat, 12 Sep 2020 14:16:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%97%A5%E5%BF%97%E6%80%BB%E7%BB%93/</guid><description>undo log 是InnoDB存储引擎独有的
想要保证事务的原子性，就需要在异常发生时，对已经执行的操作进行回滚，在 MySQL 中，恢复机制是通过 回滚日志（undo log） 实现的。
Mvcc 多版本的记录在undo log中
redo log 是InnoDB存储引擎独有的物理日志，记录内容是“在某个数据页上做了什么修改”
redo log（重做日志），它让MySQL拥有了崩溃恢复能力。
配合checkpoint循环使用
binlog binlog 是逻辑日志，记录内容是语句的原始逻辑，类似于“给 ID=2 这一行的 c 字段加 1”，属于MySQL Server 层。 二进制目志 (binary log)记录了对MySQL数据库执行更改的所有操作，但是不包 括SELECT和SHOW这类操作，因为这类操作对数据本身并没有修改。 binlog 日志有三种格式，可以通过binlog_format参数指定。
statement row mixed 用途： 恢复 (recovery):某些数据的恢复需要二进制日志，例如，在一个数据库全备文 件恢复后，用户可以通过二进制日志进行point-in-time的恢复
复制 (replication):其原理与恢复类似，通过复制和执行二进制日志使一台远程 的MySQL数据库 (一般称为slave或standby) 与一台MySQL数据库(一般称 /master或primary) 进行实时同步</description></item><item><title>单例</title><link>https://fengzhenbing.github.io/p/%E5%8D%95%E4%BE%8B/</link><pubDate>Fri, 21 Aug 2020 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/%E5%8D%95%E4%BE%8B/</guid><description>单例模式 在运行期间，保证某个类只创建一个实例，保证一个类仅有一个实例，并提供一个访问它的全局访问点
饿汉式 public class Singleton { private static Singleton instance = new Singleton(); private Singleton() { } public static Singleton getInstance() { return instance; } } 优点就是实现简单，而且安全可靠 缺点，没有懒加载，可能用不到，却实例化了 懒汉式 public class SingletonSafe { // 防止指令重排 private static volatile SingletonSafe singleton; private SingletonSafe() { } public static SingletonSafe getSingleton() { if (singleton == null) { synchronized (SingletonSafe.class) { if (singleton == null) { singleton = new SingletonSafe(); } } } return singleton; } } 双重检查，保证线程安全</description></item><item><title>分布式事务</title><link>https://fengzhenbing.github.io/p/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</link><pubDate>Thu, 13 Aug 2020 14:16:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</guid><description>两段式提交 （2 Phase Commit，2PC）
准备阶段 重操作
提交阶段 轻操作
三段式提交 （3 Phase Commit，3PC）
在事务需要回滚的场景中：三段式的性能通常是要比两段式好很多的。
但在事务能够正常提交的场景中：两者的性能都依然很差，甚至三段式因为多了一次询问，还要稍微更差一些。
CanCommit 轻操作
PreCommit 重操作
CanCommit 轻操作
TCC事务 业务侵入性强
加入业务的中间字段
Try confirm 冥等
cancel AT事务 反向sql
MQ消息最终一致性解决方案 事务消息 由于传统的处理方式无法解决消息生成者本地事务处理成功与消息发送成功两者的一致性问题，因此事务消息就诞生了，它实现了消息生成者本地事务与消息发送的原子性，保证了消息生成者本地事务处理成功与消息发送成功的最终一致性问题。
https://www.jianshu.com/p/eb571e4065ec
RocketMQ支持事务消息
生产者先发消息，再执行业务操作： 如果反过来，可能业务执行成功就宕机，消息没发出，导致不一致 事务消息是针对生产端而言的，而消费端，消费端的一致性是通过MQ的重试机制来完成的：消息消费失败的话，MQ自己会负责重推消息，直到消费成功（消费者保证幂等性）。 RocketMQ事务消息原理 MQ存储了待发送的消息，但是MQ无法感知到上游处理的最终结果。对于RocketMQ而言，它的解决方案非常的简单，就是其内部实现会有一个定时任务，去轮训状态为待发送的消息，然后给producer发送check请求，而producer必须实现一个check监听器，监听器的内容通常就是去检查与之对应的本地事务是否成功(一般就是查询DB)，如果成功了，则MQ会将消息设置为可发送，否则就删除消息。</description></item><item><title>高可用之限流</title><link>https://fengzhenbing.github.io/p/%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B9%8B%E9%99%90%E6%B5%81/</link><pubDate>Sun, 21 Jun 2020 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B9%8B%E9%99%90%E6%B5%81/</guid><description/></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description>java Unsafe 。 sun.misc.Unsafe</description></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description>什么事JMM JMM 规范明确定义了不同的线程之 间，通过哪些方式，在什么时候可以 看见其他线程保存到共享变量中的 值;以及在必要时，如何对共享变量 的访问进行同步。这样的好处是屏蔽 各种硬件平台和操作系统之间的内存 访问差异，实现了 Java 并发程序真 正的跨平台。</description></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description>强引用(StrongReference) 强引用就是我们平时创建对象，创建数组时的引用。强引用在任何时候都不会被GC回收掉。内存不足，oom
软引用(SoftReference) 软引用是在系统发生OOM之前才被JVM回收掉。软引用常被用来对于内存敏感的缓存。
弱引用(WeakReference) 一旦JVM执行GC，弱引用就会被回收掉。
(虚引用)PhantomReference 虚引用主要作为其指向referent被回收时的一种通知机制。
ReferenceQueue引用队列 用于存放待回收的引用对象（GC 会把引用对象本身添加到这个队列中）
ReferenceQueue一般用来与SoftReference、WeakReference或者PhantomReference配合使用，将需要关注的引用对象注册到引用队列后，便可以通过监控该队列来判断关注的对象是否被回收，从而执行相应的方法。
主要使用场景：
1、使用引用队列进行数据监控，类似前面栗子的用法。
2、队列监控的反向操作
参考 https://www.cnblogs.com/mfrank/p/10104586.html</description></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description>![屏幕快照 2021-09-15 上午8.50.10](https://fengzhenbing.github.io/img/picgo/屏幕快照 2021-09-15 上午8.50.10.png)</description></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description>Jmstat</description></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description>参考https://zhuanlan.zhihu.com/p/138819184
用 volatile 修饰共享变量后，每个线程要操作变量时会从主内存中将变量拷贝到本地内存作为副本，当线程操作变量副本并写回主内存后，会通过 CPU 总线嗅探机制告知其他线程该变量副本已经失效，需要重新从主内存中读取。
volatile 的主要作用有两点：
保证变量的内存可见性
禁止指令重排序</description></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description>bio 阻塞io
TCP服务端
// 启动 ServerSocket serverSocket = new ServerSocket(8080); while (!serverSocket.isClosed()) { Socket request = serverSocket.accept(); //一次请求分配一个线程: threadPool.execute(() -&amp;gt; { // 处理接收到的内容inputStream InputStream inputStream = request.getInputStream(); inputStream.read(...) ... // 向客户端发送内容 OutputStream outputStream = request.getOutputStream(); outputStream.write(...) ... } ... // 关闭 serverSocket.close(); } TCP客户端
// 启动连接 Socket s = new Socket(&amp;#34;localhost&amp;#34;, 8080); // 发送内容 OutputStream out = s.getOutputStream(); outputStream.write(...) // 处理接收的内容inputStream InputStream inputStream = s.getInputStream(); inputStream.read(...) .</description></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description>线程模型 nio 多reacto 参考 https://www.jianshu.com/p/e0e7cb085fb4
netty线程模型 eventloopgroup eventloop channel handler关系
责任链模型ChannelPipeline pipeline 持有context的双链表
context 持有下一个和上一个context和 handler , 并触发链式调用下一个或者上一个context的hander
handler 自己写的时候，继承适配器即可
整体结构 netty 内存管理 bytebuf pool https://people.freebsd.org/~jasone/jemalloc/bsdcan2006/jemalloc.pdf
引用计数。
对象回收复用栈 https://www.jianshu.com/p/854b855bd198
零拷贝 netty https://www.jianshu.com/p/0ab705ae4f2d
FileChannel.transferTo() 实现nio的零拷贝
Netty之ChannelOption参数
Netty 高性能表现在哪些方面？ IO 线程模型：同步非阻塞，用最少的资源做更多的事。
内存零拷贝：尽量减少不必要的内存拷贝，实现了更高效率的传输。
内存池设计：申请的内存可以重用，主要指直接内存。内部实现是用一颗二叉查找树管理内存分配情况。
串形化处理读写：避免使用锁带来的性能开销。
高性能序列化协议：支持 protobuf 等高性能序列化协议。</description></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description/></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description>线程状态
1 Monitor机制https://blog.csdn.net/mulinsen77/article/details/88617370 AQS
https://www.jianshu.com/p/cc308d82cc71
详解Condition的await和signal等待/通知机制
https://www.jianshu.com/p/28387056eeb4</description></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description>wget https://cdn.mysql.com/archives/mysql-5.7/mysql-5.7.26-linux-glibc2.12-x86_64.tar.gz</description></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description/></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description/></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description/></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description/></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description/></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description/></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description/></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description>1.开发任务 任务 Refactor the data structure of the registry (Xiao Yu)
* Optimize Exception printing in unit test. (Tang Zhen)
* Configuration properties front-end support for import and export (Tang Zhen).
* Websocket integration test (Zhu Kunshui)。 Finish
* Modify the plugin name style to use camel case naming (zhucongqi )
第一个字母小写。
Rpc type 不用改
显示的问题： 首
Use JSON to store PluginHandle metadata (Feng Zhenbing).
* Optimize plugin configuration (Feng Zhenbing).</description></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description/></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description/></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description>Redis内存淘汰机制 概述 Redis清除过期Key的方式 定期删除 惰性删除 Redis内存淘汰机制 概述 Redis是基于内存存储，常用于数据的缓存，所以Redis提供了对键的过期时间的设置，实现了几种淘汰机制便于适应各种场景。
设置过期时间 我们可以在设置键时设置expire time，也可以在运行时给存在的键设置剩余的生存时间，不设置则默认为-1，设置为-1时表示永久存储。
Redis清除过期Key的方式 定期删除+惰性删除
定期删除 Redis设定每隔100ms随机抽取设置了过期时间的key，并对其进行检查，如果已经过期则删除。 为什么是随机抽取？ 因为如果存储了大量数据，全部遍历一遍是非常影响性能的！
惰性删除 每次获取key时会对key进行判断是否还存活，如果已经过期了则删除。
注意：Redis中过期的key并不会马上删除，因为定期删除可能正好没抽取到它，我们也没有访问它触发惰性删除
Redis内存淘汰机制 思考一下，如果定期删除漏掉了很多过期的key，而我们也没有再去访问它，如果不加处理，很可能导致内存耗尽。
Redis配置文件中可以设置maxmemory，内存的最大使用量，到达限度时会执行内存淘汰机制。
Redis中的内存淘汰机制：
没有配置时，默认为no-eviction
名称 描述 volatile-lru 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰 volatile-lfu 从已设置过期时间的数据集中挑选最不经常使用的数据淘汰 volatile-ttl 从已设置过期时间的数据集中挑选将要过期的数据淘汰 volatile-random 从已设置过期时间的数据集中挑选任意数据淘汰 allkeys-lru 当内存不足写入新数据时淘汰最近最少使用的Key allkeys-random 当内存不足写入新数据时随机选择key淘汰 allkeys-lfu 当内存不足写入新数据时移除最不经常使用的Key no-eviction 当内存不足写入新数据时，写入操作会报错，同时不删除数据 volatile为前缀的策略都是从已过期的数据集中进行淘汰。 allkeys为前缀的策略都是面向所有key进行淘汰。 LRU（least recently used）最近最少用到的。 LFU（Least Frequently Used）最不常用的。 它们的触发条件都是Redis使用的内存达到阈值时。
原文链接：https://blog.csdn.net/weixin_43184769/article/details/90523923</description></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description>Redis作为内存中的数据结构存储，常用作数据库、缓存和消息代理。它支持数据结构，如 字符串，散列，列表，集合，带有范围查询的排序集（sorted sets），位图（bitmaps），超级日志（hyperloglogs），具有半径查询和流的地理空间索引。Redis具有内置复制，Lua脚本，LRU驱逐，事务和不同级别的磁盘持久性，并通过Redis Sentinel和Redis Cluster自动分区。
为了实现其出色的性能，Redis使用内存数据集（in-memory dataset）。
MQ应用有很多，比如ActiveMQ,RabbitMQ,Kafka等，但是也可以基于redis来实现，可以降低系统的维护成本和实现复杂度，本篇介绍redis中实现消息队列的几种方案。
基于List的 LPUSH+BRPOP 的实现 PUB/SUB，订阅/发布模式 基于Sorted-Set的实现 基于Stream类型的实现 基于异步消息队列List lpush-brpop(rpush-blpop) 使用rpush和lpush操作入队列，lpop和rpop操作出队列。
List支持多个生产者和消费者并发进出消息，每个消费者拿到都是不同的列表元素。
但是当队列为空时，lpop和rpop会一直空轮训，消耗资源；所以引入阻塞读blpop和brpop（b代表blocking），阻塞读在队列没有数据的时候进入休眠状态，
一旦数据到来则立刻醒过来，消息延迟几乎为零。
注意
你以为上面的方案很完美？还有个问题需要解决：空闲连接的问题。
如果线程一直阻塞在那里，Redis客户端的连接就成了闲置连接，闲置过久，服务器一般会主动断开连接，减少闲置资源占用，这个时候blpop和brpop或抛出异常，
所以在编写客户端消费者的时候要小心，如果捕获到异常，还有重试。
缺点：
做消费者确认ACK麻烦，不能保证消费者消费消息后是否成功处理的问题（宕机或处理异常等），通常需要维护一个Pending列表，保证消息处理确认。 不能做广播模式，如pub/sub，消息发布/订阅模型 不能重复消费，一旦消费就会被删除 不支持分组消费 如何实现：Redis应用-异步消息队列与延时队列
PUB/SUB,订阅/发布模式 SUBSCRIBE，用于订阅信道
PUBLISH，向信道发送消息
UNSUBSCRIBE，取消订阅
此模式允许生产者只生产一次消息，由中间件负责将消息复制到多个消息队列，每个消息队列由对应的消费组消费。
优点
典型的广播模式，一个消息可以发布到多个消费者
多信道订阅，消费者可以同时订阅多个信道，从而接收多类消息
消息即时发送，消息不用等待消费者读取，消费者会自动接收到信道发布的消息
缺点
消息一旦发布，不能接收。换句话就是发布时若客户端不在线，则消息丢失，不能寻回
不能保证每个消费者接收的时间是一致的
若消费者客户端出现消息积压，到一定程度，会被强制断开，导致消息意外丢失。通常发生在消息的生产远大于消费速度时
*可见，Pub/Sub 模式不适合做消息存储，消息积压类的业务，而是擅长处理广播，即时通讯，即时反馈的业务。*
基于Sorted-Set的实现 Sortes Set(有序列表)，类似于java的SortedSet和HashMap的结合体，一方面她是一个set，保证内部value的唯一性，另一方面它可以给每个value赋予一个score，代表这个value的
排序权重。内部实现是“跳跃表”。
有序集合的方案是在自己确定消息顺ID时比较常用，使用集合成员的Score来作为消息ID，保证顺序，还可以保证消息ID的单调递增。通常可以使用时间戳+序号的方案。确保了消息ID的单调递增，利用SortedSet的依据
Score排序的特征，就可以制作一个有序的消息队列了。
优点
就是可以自定义消息ID，在消息ID有意义时，比较重要。
缺点
缺点也明显，不允许重复消息（因为是集合），同时消息ID确定有错误会导致消息的顺序出错。
基于Stream类型的实现 Redis5.0
Stream为redis 5.0后新增的数据结构。支持多播的可持久化消息队列，实现借鉴了Kafka设计。
Redis Stream的结构如上图所示，它有一个消息链表，将所有加入的消息都串起来，每个消息都有一个唯一的ID和对应的内容。消息是持久化的，Redis重启后，内容还在。
每个Stream都有唯一的名称，它就是Redis的key，在我们首次使用xadd指令追加消息时自动创建。
每个Stream都可以挂多个消费组，每个消费组会有个游标last_delivered_id在Stream数组之上往前移动，表示当前消费组已经消费到哪条消息了。每个消费组都有一个Stream内唯一的名称，消费组不会自动创建，它需要单独的指令xgroup create进行创建，需要指定从Stream的某个消息ID开始消费，这个ID用来初始化last_delivered_id变量。
每个消费组(Consumer Group)的状态都是独立的，相互不受影响。也就是说同一份Stream内部的消息会被每个消费组都消费到。</description></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description/></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description>页面缓存 + 对象缓存 页面缓存：通过在手动渲染得到的html页面缓存到redis 对象缓存：包括对用户信息、商品信息、订单信息和token等数据进行缓存，利用缓存来减少对数据库的访问，大大加快查询速度。 6. 页面静态化 对商品详情和订单详情进行页面静态化处理，页面是存在html，动态数据是通过接口从服务端获取，实现前后端分离，静态页面无需连接数据库打开速度较动态页面会有明显提高
7. 本地标记 + redis预处理 + RabbitMQ异步下单 + 客户端轮询 描述：通过三级缓冲保护，1、本地标记 2、redis预处理 3、RabbitMQ异步下单，最后才会访问数据库，这样做是为了最大力度减少对数据库的访问。
实现：
在秒杀阶段使用本地标记对用户秒杀过的商品做标记，若被标记过直接返回重复秒杀，未被标记才查询redis，通过本地标记来减少对redis的访问 抢购开始前，将商品和库存数据同步到redis中，所有的抢购操作都在redis中进行处理，通过Redis预减少库存减少数据库访问 为了保护系统不受高流量的冲击而导致系统崩溃的问题，使用RabbitMQ用异步队列处理下单，实际做了一层缓冲保护，做了一个窗口模型，窗口模型会实时的刷新用户秒杀的状态。 client端用js轮询一个接口，用来获取处理状态 8. 解决超卖 描述：比如某商品的库存为1，此时用户1和用户2并发购买该商品，用户1提交订单后该商品的库存被修改为0，而此时用户2并不知道的情况下提交订单，该商品的库存再次被修改为-1，这就是超卖现象
实现：
对库存更新时，先对库存判断，只有当库存大于0才能更新库存 对用户id和商品id建立一个唯一索引，通过这种约束避免同一用户发同时两个请求秒杀到两件相同商品 实现乐观锁，给商品信息表增加一个version字段，为每一条数据加上版本。每次更新的时候version+1，并且更新时候带上版本号，当提交前版本号等于更新前版本号，说明此时没有被其他线程影响到，正常更新，如果冲突了则不会进行提交更新。当库存是足够的情况下发生乐观锁冲突就进行一定次数的重试。 9. 使用数学公式验证码 描述：点击秒杀前，先让用户输入数学公式验证码，验证正确才能进行秒杀。
好处：
防止恶意的机器人和爬虫 分散用户的请求 实现：
前端通过把商品id作为参数调用服务端创建验证码接口 服务端根据前端传过来的商品id和用户id生成验证码，并将商品id+用户id作为key，生成的验证码作为value存入redis，同时将生成的验证码输入图片写入imageIO让前端展示 将用户输入的验证码与根据商品id+用户id从redis查询到的验证码对比，相同就返回验证成功，进入秒杀；不同或从redis查询的验证码为空都返回验证失败，刷新验证码重试 10. 使用RateLimiter实现限流 描述：当我们去秒杀一些商品时，此时可能会因为访问量太大而导致系统崩溃，此时要使用限流来进行限制访问量，当达到限流阀值，后续请求会被降级；降级后的处理方案可以是：返回排队页面（高峰期访问太频繁，等一会重试）、错误页等。
实现：项目使用RateLimiter来实现限流，RateLimiter是guava提供的基于令牌桶算法的限流实现类，通过调整生成token的速率来限制用户频繁访问秒杀页面，从而达到防止超大流量冲垮系统。（令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务）</description></item><item><title>redis基础</title><link>https://fengzhenbing.github.io/p/redis%E5%9F%BA%E7%A1%80/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/redis%E5%9F%BA%E7%A1%80/</guid><description>redis线程 redis做为一个进程，一直是多线程的。处理io和处理内存的是不同线程。
io线程
redis6之前(2020.05)：io处理是单线程
redis6：io处理多线程，采用nio模型 =&amp;gt; 主要的性能提升点
内存处理线程
单线程 =&amp;gt;高性能核心，不用考虑线程调度 压测redis-benchmark 环境mac 4核8g mokernetdeMac-mini:redis-6.0.9 mokernet$ ./bin/redis-benchmark -n 100000 -c 32 -t SET,GET,INCR,HSET,LPUSH,MSET -q SET: 121065.38 requests per second GET: 118764.84 requests per second INCR: 117508.81 requests per second LPUSH: 123001.23 requests per second HSET: 123915.74 requests per second MSET (10 keys): 96711.80 requests per second redis的5种基本数据结构 https://redis.</description></item></channel></rss>