<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Feng Zhenbing's Blog</title><link>https://fengzhenbing.github.io/post/</link><description>Recent content in Posts on Feng Zhenbing's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 05 Sep 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://fengzhenbing.github.io/post/index.xml" rel="self" type="application/rss+xml"/><item><title>shardingsphere（5.0.0.beta）元数据上下文</title><link>https://fengzhenbing.github.io/p/shardingsphere5.0.0.beta%E5%85%83%E6%95%B0%E6%8D%AE%E4%B8%8A%E4%B8%8B%E6%96%87/</link><pubDate>Sun, 05 Sep 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/shardingsphere5.0.0.beta%E5%85%83%E6%95%B0%E6%8D%AE%E4%B8%8A%E4%B8%8B%E6%96%87/</guid><description>Shardingsphere（5.0.0.beta）源码学习-元数据上下文 上下文对象 上下文对象作为读取并解析配置, 承载数据的核心；
spring有ApplicationContext,netty有HandlerContext
向其他中间件一样，在ShardingSphere也十分重要; 后续几乎所有功能比如数据分片、数据加密、SQL 改写，各类扩展都依赖上下文对象存储的数据
标准元数据上下文 StandardMetaDataContexts 核心存储了ShardingSphereMetaData元数据集合，作为重点后面分析
@Getter public final class StandardMetaDataContexts implements MetaDataContexts { // 元数据集合 private final Map&amp;lt;String, ShardingSphereMetaData&amp;gt; metaDataMap; private final ShardingSphereRuleMetaData globalRuleMetaData; // 执行引擎 private final ExecutorEngine executorEngine; //优化引擎上下文工厂 private final OptimizeContextFactory optimizeContextFactory; private final ConfigurationProperties props; // 状态上下文 private final StateContext stateContext; ... } 治理元数据上下文 StandardMetaDataContexts 其实也是用的标准的StandardMetaDataContexts，治理模块shardingsphere-governance使用该上下文，通过配置中心读取规则配置，
注入到StandardMetaDataContexts中，GovernanceFacade是配置中心的门面模式，目前支持了zookeeper和etcd,其实还可以通过RegistryCenterRepository的spi实现其他的配置中心，比如nacos, apollo,consul等。
public final class GovernanceMetaDataContexts implements MetaDataContexts { //治理： 配置中心的门面模式 private final GovernanceFacade governanceFacade; //还是使用StandardMetaDataContexts 装饰器模式 private volatile StandardMetaDataContexts metaDataContexts; private final ShardingSphereLock lock; .</description></item><item><title>shardingsphere（5.0.0.beta）源码总览</title><link>https://fengzhenbing.github.io/p/shardingsphere5.0.0.beta%E6%BA%90%E7%A0%81%E6%80%BB%E8%A7%88/</link><pubDate>Thu, 02 Sep 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/shardingsphere5.0.0.beta%E6%BA%90%E7%A0%81%E6%80%BB%E8%A7%88/</guid><description>Shardingsphere（5.0.0.beta）源码学习-总览 shardingsphere作为极为优秀的开源分布式数据库解决方案，通过阅读源码可以学到很多软件设计与开发的知识。
本次我继续按照之前读源码的方式从整体到细节，带着问题读源码的方式记录这次深入学习 shardingsphere的过程。
源码版本 5.0.0.beta 官方文档 源码地址 https://github.com/apache/shardingsphere/tree/5.0.0-beta 项目结构 先大概理解各个模块的主要功能点
一级目录 说明 examples 各种使用例子 shardingsphere-agent 监控, 对接apm,链路追踪 shardingsphere-db-protocol 数据库协议 shardingsphere-distribution 相关打包发步用 shardingsphere-distsql-parser distsql新功能:ShardingSphere 特有的内置 SQL 语言，提供了标准 SQL 之外的增量功能操作能力。 shardingsphere-features 常用功能shardingsphere-db-discovery 基于MGR主从切换的功能shardingsphere-encrypt 加解密shardingsphere-readwrite-splitting 读写分离 **重点**shardingsphere-shadow 影子库shardingsphere-sharding 分库分表 **重点** shardingsphere-governance 数据治理：结合注册中心，提供给前端页面使用 shardingsphere-infra 引擎内核：shardingsphere-infra-authority proxy的权限控制shardingsphere-infra-binder sql解析后的结果绑定封装SQLStatement封装为各类上下文contextshardingsphere-infra-common 重要的实体类及工具 的元数据metadata,SPI,yaml工具，rule接口等shardingsphere-infra-context 上下文相关shardingsphere-infra-datetime 时间服务shardingsphere-infra-executor 执行器引擎 **重点**shardingsphere-infra-merge 归并引擎**重点**shardingsphere-infra-optimize 优化引擎**重点**shardingsphere-infra-parser 解析引擎**重点**shardingsphere-infra-rewrite 改写引擎**重点**shardingsphere-infra-route 路由引擎**重点** shardingsphere-jdbc jdbc核心功能：增强版的 JDBC 驱动，完全兼容 JDBC 和各种 ORM 框架。装饰器模式，对原生的DataSource,Connection,Statement(PrepareStatement),ResultSet进行包装， shardingsphere-proxy 透明化的数据库代理提供封装了数据库二进制协议的服务端版本，用于完成对异构语言的支持 shardingsphere-scaling 数据迁移相关:弹性伸缩 shardingsphere-sql-parser sql解析器：antlr4 词法语法解析出SqlStatement,提供各类数据库的方言实现。SQL 解析作为分库分表类产品的核心，其性能和兼容性是最重要的衡量指标 shardingsphere-test 测试引擎 shardingsphere-transaction 事务：整合现有的成熟事务方案，本地事务、两阶段事务（XA）和柔性事务（Seata AT 事务）提供统一的分布式事务接口 对于重点核心内容有个大致认识，后面再单独分模块分析。</description></item><item><title>分布式任务调度Hodor</title><link>https://fengzhenbing.github.io/p/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6hodor/</link><pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6hodor/</guid><description>分布式任务调度Hodor源码分析（整体结构） 简介 Hodor是一个高性能的分布式任务调度框架。
github地址(https://github.com/tincopper/hodor)
架构图 因无任何文档，以下架构图纯阅读源码个人理解后手工所画：
代码目录及分析 hodor-admin
待开发：配合前端页面做任务展示
hodor-client
客户端，用户app通过该客户端将任务信息提交到hodor-server，供其调度
集成了nettyserver服务，接收来自hodor-server的任务执行请求
hodor-client-demo
用户app示例：集成了hodor-client
hodor-common
通用库
环形队列 观察者模式（事件发布监听）模型 Excutor：多线程封装 Extension: SPI扩展方式封装 负载均衡 存储：本地缓存/mysql/h2 异常 日志 Distributor高性能队列 hodor-core
简单的spring mybatis 工程：对任务/任务执行记录等数据入库（mysql）
hodor-extension
hodor-model
实体
hodor-register
注册中心封装，目前只实现了zookeeper
hodor-register-api Hodor-register-zookeeper hodor-remoting
netty http客户端
netty http服务端
hodor-scheduler
任务定时的封装</description></item><item><title>docusaurus构建website</title><link>https://fengzhenbing.github.io/p/docusaurus%E6%9E%84%E5%BB%BAwebsite/</link><pubDate>Sun, 22 Aug 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/docusaurus%E6%9E%84%E5%BB%BAwebsite/</guid><description>docusaurus构建website 环境 Node.js version &amp;gt;= 12.13.0 以上(node -v 查看)，使用了国际化i18n，则Node.js version &amp;gt;=14以上
Yarn version &amp;gt;= 1.5 ( yarn &amp;ndash;version查看). mac下可以使用n管理node版本
Title logo等文案，首页展示 待讨论
菜单调整 Nav : 文档 社区 新闻 博客 links 国际化切换 搜索
Documentation Community News Blog Links
Footer:
首页 下载按钮 文档按钮 star按钮修改
样式修改
国际化语言 yarn write-translations --locale zh 参考https://docusaurus.io/zh-CN/docs/cli#docusaurus-write-translations-sitedir
中英文两个版本的文件名称保持一致。文档中没有指定sidebar_position时，默认按文件名称在菜单栏排序</description></item><item><title>开放平台appKey，appSecret设计</title><link>https://fengzhenbing.github.io/p/%E5%BC%80%E6%94%BE%E5%B9%B3%E5%8F%B0appkeyappsecret%E8%AE%BE%E8%AE%A1/</link><pubDate>Thu, 19 Aug 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/%E5%BC%80%E6%94%BE%E5%B9%B3%E5%8F%B0appkeyappsecret%E8%AE%BE%E8%AE%A1/</guid><description>开放平台appKey appSecret设计 1，手动注册客户端，服务端返回appKey appSecret 客户端和服务端都保存ak as 2, 客户端第一次请求 通过appKey请求token 服务端通过appKey，appSecret，时间戳，用户的必要信息生成token，可以使用JWTToken.
​ token具有有效期：Token是客户端访问服务端的凭证。
3，客户端后续请求 参数为： Token + 当前时间戳 + 参数 +签名sign1
签名sign1为 Token + 当前时间戳 + 参数+appSecret 按照一定签名算法比如 SHA256生成的签名字符串，为了保证请求中参数不被流量劫持篡改
4，服务端收到请求进行校验 时间戳校验：请求时间和当前服务端时间大于一定范围，比如5分钟，拒绝执行 Token解析：token过期拒绝执行 签名校验： 通过token解析获取到appKey，再获取到appSecret， 使用与客户端相同的签名算法SHA256得到签名sign2, 如果sign1不等于sign2，拒绝执行</description></item><item><title>Prometheus监控JVM</title><link>https://fengzhenbing.github.io/p/prometheus%E7%9B%91%E6%8E%A7jvm/</link><pubDate>Sun, 15 Aug 2021 14:16:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/prometheus%E7%9B%91%E6%8E%A7jvm/</guid><description>1. jmx_exporter 下载jmx_exporter ubuntu:/# mkdir -p /usr/local/prometheus/jmx_exporter ubuntu:/# cd /usr/local/prometheus/jmx_exporter ubuntu:/# wget https://repo1.maven.org/maven2/io/prometheus/jmx/jmx_prometheus_javaagent/0.16.1/jmx_prometheus_javaagent-0.16.1.jar 配置文件jmx_exporter jmx_exporter.yml
vim /usr/local/prometheus/jmx_exporter/jmx_exporter.yml --- rules: - pattern: &amp;quot;.*&amp;quot; java agent运行jmx_exporter 以java agent的方式启动你的一个java应用
java -javaagent:/usr/local/prometheus/jmx_prometheus_javaagent-0.16.1.jar=3010:/usr/local/prometheus/jmx_exporter.yml -jar xxx-web-0.1-SNAPSHOT.jar 2. prometheus docker方式下载运行 # docker pull prom/prometheus #下载docker镜像 # mkdir -p /etc/prometheus # vim /etc/prometheus/prometheus.yml #配置 # docker run -d \ -p 192.168.3.13:9090:9090 \ -v /etc/prometheus:/etc/prometheus \ prom/prometheus; prometheus中配置上步的jmx的metrics global:scrape_interval:15sscrape_timeout:10sevaluation_interval:15salerting:alertmanagers:- follow_redirects:truescheme:httptimeout:10sapi_version:v2static_configs:- targets:[]scrape_configs:- job_name:prometheushonor_timestamps:truescrape_interval:15sscrape_timeout:10smetrics_path:/metricsscheme:httpfollow_redirects:truestatic_configs:- targets:- 192.168.3.13:9090### 以下为jmx_exporter地址：需改为你实际的- job_name:&amp;#39;jmx&amp;#39;static_configs:scrape_interval:15s- targets:[&amp;#39;192.</description></item><item><title>mac下node升级</title><link>https://fengzhenbing.github.io/p/mac%E4%B8%8Bnode%E5%8D%87%E7%BA%A7/</link><pubDate>Wed, 21 Jul 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/mac%E4%B8%8Bnode%E5%8D%87%E7%BA%A7/</guid><description># 清除nodejs的cache sudo npm cache clean -f # 由于您可能已经拥有node，最简单的安装方式n是npm： sudo npm install -g n # node所有版本 npm view node versions # 升级到最新版本 sudo n latest # 升级到稳定版本 sudo n stable # 升级到具体版本号 sudo n xx.xx</description></item><item><title>Disruptor高性能队列</title><link>https://fengzhenbing.github.io/p/disruptor%E9%AB%98%E6%80%A7%E8%83%BD%E9%98%9F%E5%88%97/</link><pubDate>Tue, 20 Jul 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/disruptor%E9%AB%98%E6%80%A7%E8%83%BD%E9%98%9F%E5%88%97/</guid><description>Disruptor通过以下设计来解决队列速度慢的问题： 环形数组结构
元素位置定位
数组长度2^n， 位运算，加快定位的速度
无锁设计
Cas操作保证线程安全
参考 https://tech.meituan.com/2016/11/18/disruptor.html
https://blog.csdn.net/liweisnake/article/details/9113119</description></item><item><title>Envoy</title><link>https://fengzhenbing.github.io/p/envoy/</link><pubDate>Tue, 20 Jul 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/envoy/</guid><description>Envoy概述 Envoy 是以 C++ 开发的高性能代理;
其内置服务发现、负载均衡、TLS终止、HTTP/2、GRPC代理、熔断器、健康检查，基于百分比流量拆分的灰度发布、故障注入等功能
Downstream：下游主机，指连接到Envoy的主机，这些主机用来发送请求并接受响应。 Upstream：上游主机，指接收来自Envoy连接和请求的主机，并返回响应。 Listener：服务或程序的监听器， Envoy暴露一个或多个监听器监听下游主机的请求，当监听到请求时，通过Filter Chain把对请求的处理全部抽象为Filter， 例如ReadFilter、WriteFilter、HttpFilter等。 Cluster：服务提供集群，指Envoy连接的一组逻辑相同的上游主机。Envoy通过服务发现功能来发现集群内的成员，通过负载均衡功能将流量路由到集群的各个成员。 xDS：xDS中的x是一个代词，类似云计算里的XaaS可以指代IaaS、PaaS、SaaS等。DS为Discovery Service，即发现服务的意思。xDS包括CDS（cluster discovery service）、RDS（route discovery service）、EDS（endpoint discovery service）、ADS（aggregated discovery service），其中ADS称为聚合的发现服务，是对CDS、RDS、LDS、EDS服务的统一封装，解决CDS、RDS、LDS、EDS信息更新顺序依赖的问题，从而保证以一定的顺序同步各类配置信息。以上Endpoint、Cluster、Route的概念介绍如下： Endpoint：一个具体的“应用实例”，类似于Kubernetes中的一个Pod； Cluster：可以理解“应用集群”，对应提供相同服务的一个或多个Endpoint， 类似Kubernetes中Service概念，即一个Service提供多个相同服务的Pod； Route：当我们做金丝雀发布部署时，同一个服务会有多个版本，这时需要Route规则规定请求如何路由到其中的某个版本上。 http://www.dockone.io/article/9116</description></item><item><title>加密算法</title><link>https://fengzhenbing.github.io/p/%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/</link><pubDate>Mon, 21 Jun 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/</guid><description>哈希摘要算法 好的哈希摘要算法需要具备
一是易变性，这是指算法的输入端发生了任何一点细微变动，都会引发雪崩效应,使得输出端的结果产生极大的变化
常常被用来校验数据是否被篡改
二是不可逆性，摘要的过程是单向的，不可能从摘要的结果中逆向还原出输入值来
对称加密和非对称加密 对称加密 对称加密指的就是加密和解密使用同一个秘钥，所以叫做对称加密。对称加密只有一个秘钥，作为私钥。 常见的对称加密算法：DES，3DES，AES等等。
非对称加密 非对称加密指的是：加密和解密使用不同的秘钥，一把作为公开的公钥，另一把作为私钥。公钥加密的信息，只有私钥才能解密。私钥加密的信息，只有公钥才能解密。 常见的非对称加密算法：RSA，ECC
区别 对称加密算法相比非对称加密算法来说，加解密的效率要高得多。但是缺陷在于对于秘钥的管理上，以及在非安全信道中通讯时，密钥交换的安全性不能保障。所以在实际的网络环境中，会将两者混合使用.
对称加密传输大量数据
非对称加密永远对称加密的密钥协商，传输。
例如针对C/S模型，
服务端计算出一对秘钥pub/pri。将私钥保密，将公钥公开。 客户端请求服务端时，拿到服务端的公钥pub。 客户端通过AES计算出一个对称加密的秘钥X。 然后使用pub将X进行加密。 客户端将加密后的密文发送给服务端。服务端通过pri解密获得X。 然后两边的通讯内容就通过对称密钥X以对称加密算法来加解密。
三种密码学算法的对比 类型 特点 常见实现 主要用途 主要局限 哈希摘要 不可逆，即不能解密，所以并不是加密算法，只是一些场景把它当作加密算法使用。 易变性，输入发生 1 Bit 变动，就可能导致输出结果 50%的内容发生改变。 无论输入长度多少，输出长度固定（2 的 N 次幂）。 MD2/4/5/6、SHA0/1/256/512 摘要 无法解密 对称加密 加密是指加密和解密是一样的密钥。 设计难度相对较小，执行速度相对较块。 加密明文长度不受限制。 DES、AES、RC4、IDEA 加密 要解决如何把密钥安全地传递给解密者。 非对称加密 加密和解密使用的是不同的密钥。 明文长度不能超过公钥长度。 RSA、BCDSA、ElGamal 签名、传递密钥 性能与加密明文长度受限。 数字证书 解决公钥被劫持篡改的问题。由权威机构颁发保证</description></item><item><title>图解shenyu</title><link>https://fengzhenbing.github.io/p/%E5%9B%BE%E8%A7%A3shenyu/</link><pubDate>Sat, 19 Jun 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/%E5%9B%BE%E8%A7%A3shenyu/</guid><description>spi 数据同步 请求执行路径 服务调用 admin定时探活</description></item><item><title>服务链路追踪</title><link>https://fengzhenbing.github.io/p/%E6%9C%8D%E5%8A%A1%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA/</link><pubDate>Sat, 12 Jun 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/%E6%9C%8D%E5%8A%A1%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA/</guid><description>背景 随着业务的发展，系统规模也会越来越大，各微服务间的调用关系也越来越错综复杂，每一个前端请求都会形成一条复杂的分布式服务调用链路，在每条链路中任何一个依赖服务出现延迟过高或错误的时候都会引起请求最后的失败。
链路追踪原理 实现请求跟踪 当请求发送到分布式系统的入口端点时，只需要服务跟踪框架为该请求创建一个唯一的跟踪标识Trace ID，
同时在分布式系统内部流转的时候，框架失踪保持该唯一标识，直到返回给请求方位置。
trace：服务追踪的追踪单元是从客户发起请求（request）抵达被追踪系统的边界开始，到被追踪系统向客户返回响应（response）为止的过程，称为一
个“trace”
统计各处理单元的时间延迟 当请求到达各个服务组件时，也是通过一个唯一标识Span ID来标记它的开始，具体过程以及结束。对每一个Span来说，它必须有开始和结束两个节点，通过记录开始Span和结束Span的时间戳，就能统计出该Span的时间延迟，除了时间戳记录之外，它还可以包含一些其他元数据，比如时间名称、请求信息等。
UI可视化 APM技术组件 Zipkin+Sleuth Apache SkyWalking Cat Pinpoint 特点对比</description></item><item><title>k8s Kubectl命令</title><link>https://fengzhenbing.github.io/p/k8s-kubectl%E5%91%BD%E4%BB%A4/</link><pubDate>Thu, 10 Jun 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/k8s-kubectl%E5%91%BD%E4%BB%A4/</guid><description>kubelet日志 journalctl -fu kubelet kubectl -h kubectl get namespaces kubectl get pods -A kubectl logs -f --tail=200 -l app=account -n bookstore-microservices 常用命令 #查看端口映射 kubectl get svc -n kube-system #查看 secret kubectl get secret -n kube-system #查看 token kubectl describe secret kubernetes-dashboard --namespace=kube-system #k8s 无法启动，查看日志，查找Failed journalctl -xefu kubelet #查看pod错误日志 kubectl logs kubernetes-dashboard-8556c848b7-4kpzd --namespace=kube-system #对资源进行配置 kubectl apply -f kubernetes-dashboard.yaml kubectl delete -f kubernetes-dashboard.ya YAML配置文件管理对象 对象管理： # 创建deployment资源 kubectl create -f nginx-deployment.yaml # 查看deployment kubectl get deploy # 查看ReplicaSet kubectl get rs # 查看pods所有标签 kubectl get pods --show-labels # 根据标签查看pods kubectl get pods -l app=nginx # 滚动更新镜像 kubectl set image deployment/nginx-deployment nginx=nginx:1.</description></item><item><title>架构演变</title><link>https://fengzhenbing.github.io/p/%E6%9E%B6%E6%9E%84%E6%BC%94%E5%8F%98/</link><pubDate>Thu, 10 Jun 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/%E6%9E%B6%E6%9E%84%E6%BC%94%E5%8F%98/</guid><description>单体架构(spring boot) 优点：所有代码都运行在同一个进程空间之内，所有模块、方法的调用都无须考虑网络分区、对象复制这些麻烦的事和性能损失。
缺点：损失了各个功能模块的自治、隔离能力；
​ 由于隔离能力的缺失难以阻断错误传播、不便于动态更新程序以外，还面临难以技术异构的困难
​ 可以 使用OSGi 这种运行时模块化框架，但是太复杂了。
SOA 架构（Service-Oriented Architecture） 面向服务的架构是一次具体地、系统性地成功解决分布式服务主要问题的架构模式。
SOAP 协议被逐渐边缘化的本质原因：过于严格的规范定义带来过度的复杂性。而构建在 SOAP 基础之上的 ESB、BPM、SCA、SDO 等诸多上层建筑，进一步加剧了这种复杂性。
微服务架构(spring cloud) 微服务是一种软件开发技术，是一种 SOA 的变体形式。
升级背景：
制约软件质量与业务能力提升的最大因素是人而非硬件： 单体架构没有什么有效阻断错误传播的手段 技术异构的需求从可选渐渐成为必须：很多 Java 不擅长的事情 人工智能python 分布式协调工具 Etcd ,NSI C 编写的 Redis， &amp;hellip; 由于隔离能力的缺失，单体除了难以阻断错误传播、不便于动态更新程序以外，还面临难以技术异构的困难，每个模块的代码都通常需要使用一样的程序语言，乃至一样的编程框架去开发。
随着软件架构演进，构筑可靠系统从“追求尽量不出错”，到正视“出错是必然”的观念转变，才是微服务架构得以挑战并逐步开始取代运作了数十年的单体架构的底气所在
微服务时代充满着自由的气息，微服务时代充斥着迷茫的选择。
微服务架构(Kubernetes) 升级背景：
微服务中的各种新技术名词，如配置中心、服务发现、网关、熔断、负载均衡等等带来的技术组件 Config、Eureka、Zuul、Hystrix、Ribbon、Feign 等
占据了产品的大部分编译后的代码容量
之前在应用层面而不是基础设施层面去解决这些分布式问题，完全是因为由硬件构成的基础设施，跟不上由软件构成的应用服务的灵活性的无奈之举
以 Docker Swarm、Apache Mesos 与 Kubernetes 为主要竞争者的“容器战争”终于有了明确的结果，Kubernetes 登基加冕
容器动态构建出 DNS 服务器、服务负载均衡器等一系列虚拟化的基础设施，去代替原有的应用层面的技术组件</description></item><item><title>Kubeadm安装Kubernetes</title><link>https://fengzhenbing.github.io/p/kubeadm%E5%AE%89%E8%A3%85kubernetes/</link><pubDate>Tue, 08 Jun 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/kubeadm%E5%AE%89%E8%A3%85kubernetes/</guid><description>1.环境准备 安装 Kubernetes 最小需要 2 核处理器、2 GB 内存，且为 x86 架构（暂不支持 ARM 架构)
本次实验操作系统：ubantu 20.04LTS
Kubernetes 并不在主流 Debian 系统自带的软件源中，所以要手工注册，然后才能使用apt-get安装
# 添加GPG Key $ sudo curl -fsSL https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - # 添加K8S软件源 $ sudo add-apt-repository &amp;#34;deb https://apt.kubernetes.io/ kubernetes-xenial main&amp;#34; 如果不能科学上网，可以使用阿里云的软件源地址
# 添加GPG Key $ curl -fsSL http://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo apt-key add - # 添加K8S软件源 $ sudo add-apt-repository &amp;#34;deb http://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial main&amp;#34; 添加源后需要更新
sudo apt-get update 2. 安装 kubelet、kubectl、kubeadm 官网介绍：https://kubernetes.io/docs/reference/setup-tools/kubeadm/</description></item><item><title>优雅停机</title><link>https://fengzhenbing.github.io/p/%E4%BC%98%E9%9B%85%E5%81%9C%E6%9C%BA/</link><pubDate>Wed, 19 May 2021 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/%E4%BC%98%E9%9B%85%E5%81%9C%E6%9C%BA/</guid><description>1, ShutdownHook初识 在Java程序中可以通过添加关闭钩子，实现在程序退出时关闭资源、平滑退出的功能。 并且在以下几种场景将调用该钩子
程序正常退出 使用System.exit() 终端使用Ctrl+C触发的中断 系统关闭 使用Kill pid命令干掉进程 具体来讲Runtime.addShutdownHook 添加钩子到 ApplicationShutdownHooks中。
// Runtime添加钩子（钩子具体来讲就是一个要执行的线程任务） public void addShutdownHook(Thread hook) { SecurityManager sm = System.getSecurityManager(); if (sm != null) { sm.checkPermission(new RuntimePermission(&amp;#34;shutdownHooks&amp;#34;)); } ApplicationShutdownHooks.add(hook); } // Runtime去除钩子 public boolean removeShutdownHook(Thread hook) { SecurityManager sm = System.getSecurityManager(); if (sm != null) { sm.checkPermission(new RuntimePermission(&amp;#34;shutdownHooks&amp;#34;)); } return ApplicationShutdownHooks.remove(hook); } 再看ApplicationShutdownHooks
class ApplicationShutdownHooks { /* The set of registered hooks */ private static IdentityHashMap&amp;lt;Thread, Thread&amp;gt; hooks; static { try { Shutdown.</description></item><item><title>jvm垃圾回收</title><link>https://fengzhenbing.github.io/p/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/</link><pubDate>Sun, 14 Mar 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/</guid><description>jvm垃圾回收 对象存活判断算法 引用计数算法 问题： 可能存在两个对象相互引用，导致无法回收，内存泄漏
根可达算法 维护引用的链表； 如果某个对象无法到达根节点，说明可以被回收
垃圾回收算法 对停顿时间(延时)和吞吐量的权衡，没有最好，只有最适合当前业务场景的回收方式
针对 堆内存回收；
方法区
java 8 前 永久区（也参与垃圾回收，一样的算法，省事了，但是有默认最大内存限制，容易oom） java 8 彻底抛弃了 永久区，叫元数据区，使用本地内存 分代收集理论 新生代
老年代
跨代引用： Remember set
标记清除 产生内存碎片，内存分配复杂了。 可能需要类似硬盘的 “分区空闲分配链表” 等复杂方式解决
Cms搜集器在old 区回收时采用， 但是内存碎片达到一定量，会采取一次标记整理。（和稀泥的做法，结合两者，）
标记复制 一般用于新生代回收: Serial ParNew 的新生代采用该算法
scurvivorRadio Ēden survivor survivor 8:1:1
对象存活率较高时，需要更多的复制操作，效率会降低
标记整理 用于old区：
相对于 标记清除， 标记后，需要移动：将存活的对象移动到内存区域的一端。
移动：增大的延迟，stw时间长些，但解决了内存碎片，内存分配复杂的问题，可以提高吞吐量。
不移动：降低了延迟，但内存碎片，内存分配复杂， 吞吐量有所下降。
垃圾回收器 对于新生代一般时使用标记复制算法</description></item><item><title>pulsar</title><link>https://fengzhenbing.github.io/p/pulsar/</link><pubDate>Tue, 23 Feb 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/pulsar/</guid><description>相关概念 计算存储分离 安装测试 # 下载 wget https://mirrors.bfsu.edu.cn/apache/pulsar/pulsar-2.7.1/apache-pulsar-2.7.1-bin.tar.gz tar xvfz apache-pulsar-2.7.1-bin.tar.gz cd apache-pulsar-2.7.1 # 单机启动 bin/pulsar standalone # 消费消息 bin/pulsar-client consume my-topic -s &amp;#34;first-subscription&amp;#34; # 生产消息 bin/pulsar-client produce my-topic --messages &amp;#34;hello-pulsar&amp;#34; 相关资料 官网快速启动</description></item><item><title>rocketMQ</title><link>https://fengzhenbing.github.io/p/rocketmq/</link><pubDate>Sat, 20 Feb 2021 09:16:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/rocketmq/</guid><description>相关概念 二代mq, 纯java开发，和kafka无本质区别
安装测试 # 下载 4.8.0 wget https://downloads.apache.org/rocketmq/4.8.0/rocketmq-all-4.8.0-bin-release.zip unzip rocketmq-all-4.8.0-bin-release.zip #运行命名服务， 替代kafka的zk nohup sh bin/mqnamesrv &amp;amp; #查看日志 tail -f ~/logs/rocketmqlogs/namesrv.log #运行broker nohup sh bin/mqbroker -n localhost:9876 &amp;amp; #查看日志 tail -f ~/logs/rocketmqlogs/broker.log # 发送消息 export NAMESRV_ADDR=localhost:9876 sh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer #消费消息 sh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer 相关资料 官网快速开始
中文文档</description></item><item><title>rabbitMQ</title><link>https://fengzhenbing.github.io/p/rabbitmq/</link><pubDate>Fri, 19 Feb 2021 10:16:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/rabbitmq/</guid><description>Rabbitmq相关概念 一代mq，erlang开发， 改进activemq
Publisher 消息生产者, 返送消息时指定exchange 和routing key, 即可以将消息路由到匹配的queue中 Routing key Binding 通过routing key 将queue和exchange绑定 Exchange 工具人。。交易所。。代理 FanoutExchange: 将消息分发到所有的绑定队列，无routingkey的概念，发送时不指定routing key HeadersExchange ：通过添加属性key-value匹配 DirectExchange: 按照routingkey分发到指定队列 TopicExchange:多关键字匹配 正则 Consumer Docker方式安装运行 docker pull rabbitmq:management docker run -itd --name rabbitmq-test -e RABBITMQ_DEFAULT_USER=admin -e RABBITMQ_DEFAULT_PASS=admin -p 15672:15672 -p 5672:5672 rabbitmq:management docker exec -it rabbitmq-test /bin/bash</description></item><item><title>康威定律</title><link>https://fengzhenbing.github.io/p/%E5%BA%B7%E5%A8%81%E5%AE%9A%E5%BE%8B/</link><pubDate>Wed, 13 Jan 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/%E5%BA%B7%E5%A8%81%E5%AE%9A%E5%BE%8B/</guid><description>康威定律：组织决定产品形态 第一定律 组织设计的产品/设计等价于这个组织的沟通结构。
第二定律 时间再多一件事情也不可能做的完美，但总有时间做完一件事情
第三定律 线型系统和线型组织架构间有潜在的异质同态特性
第四定律 大的系统组织总是比小系统更倾向于分解</description></item><item><title>Synchronized锁</title><link>https://fengzhenbing.github.io/p/synchronized%E9%94%81/</link><pubDate>Tue, 15 Dec 2020 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/synchronized%E9%94%81/</guid><description>Synchronized Object.wait()：释放当前对象锁，并进入阻塞队列(wait set) Object.notify()：唤醒当前对象阻塞队列(wait set)里的任一线程（并不保证唤醒哪一个） Object.notifyAll()：唤醒当前对象阻塞队列(wait set)里的所有线程, 进到entry set 去竞争锁 为什么wait,notify和notifyAll要与synchronized一起使用？ Wait 只有通过synchronized拿到锁，才能进入wait set
notify notifyAll只有通过synchronized拿到锁，才能去唤醒 wait set 里线程 到entry set
object monitor 对象在内存中的存储 Markword 32位jvm 结构如下： 重量级锁即为 Synchronized 的锁
锁升级 参考 https://mp.weixin.qq.com/s/2yxexZUr5MWdMZ02GCSwdA</description></item><item><title>hazelcast</title><link>https://fengzhenbing.github.io/p/hazelcast/</link><pubDate>Mon, 14 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/hazelcast/</guid><description>安装 docker docker pull hazelcast/hazelcast docker run -e HZ_NETWORK_PUBLICADDRESS=192.168.3.14:5701 -p 5701:5701 hazelcast/hazelcast:$HAZELCAST_VERSION docker run -e HZ_NETWORK_PUBLICADDRESS=192.168.3.14:5702 -p 5702:5701 hazelcast/hazelcast:$HAZELCAST_VERSION docker run -p 8080:8080 hazelcast/management-center</description></item><item><title>redis应用场景</title><link>https://fengzhenbing.github.io/p/redis%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/</link><pubDate>Sun, 13 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/redis%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/</guid><description>一.业务数据缓存* 经典用法。
通用数据缓存，string，int，list，map等。
验证码等 实时热数据，最新500条数据。
如热搜新闻。。 会话缓存，token缓存等。
spring-session-data-redis sesion共享 二.业务数据处理 非严格一致性要求的数据
评论，点击，点赞等。
set key 0 incr key // incr readcount::{帖子id} 每阅读一次 get key // get readcount::{帖子id} 获取阅读量 业务数据去重
订单处理的幂等校验等。 如订单id放到redis 的set中去重复， bitmap 等 业务数据排序
排名，排行榜等。 使用sortedset 三.全局一致计数 * 全局流控计数</description></item><item><title>redis基础</title><link>https://fengzhenbing.github.io/p/redis%E5%9F%BA%E7%A1%80/</link><pubDate>Fri, 11 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/redis%E5%9F%BA%E7%A1%80/</guid><description>redis线程 redis做为一个进程，一直是多线程的。处理io和处理内存的是不同线程。
io线程
redis6之前(2020.05)：io处理是单线程
redis6：io处理多线程，采用nio模型 =&amp;gt; 主要的性能提升点
内存处理线程
单线程 =&amp;gt;高性能核心，不用考虑线程调度 压测redis-benchmark 环境mac 4核8g mokernetdeMac-mini:redis-6.0.9 mokernet$ ./bin/redis-benchmark -n 100000 -c 32 -t SET,GET,INCR,HSET,LPUSH,MSET -q SET: 121065.38 requests per second GET: 118764.84 requests per second INCR: 117508.81 requests per second LPUSH: 123001.23 requests per second HSET: 123915.74 requests per second MSET (10 keys): 96711.80 requests per second redis的5种基本数据结构 https://redis.</description></item><item><title>01.gateway整体逻辑</title><link>https://fengzhenbing.github.io/p/01.gateway%E6%95%B4%E4%BD%93%E9%80%BB%E8%BE%91/</link><pubDate>Thu, 10 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/01.gateway%E6%95%B4%E4%BD%93%E9%80%BB%E8%BE%91/</guid><description>gateway整体逻辑 1.流程图 2.几个关键的类 org.springframework.web.reactive.DispatcherHandler: 请求分发处理器； Spring WebFlux 的访问入口； 类似于spring mvc DispatcherServlet,可以类比spring mvc 接收到请求; DispatcherHandler匹配 HandlerMapping此处会匹配到scg的RoutePredicateHandlerMapping org.springframework.cloud.gateway.handler.RoutePredicateHandlerMapping：HandlerMapping的实现；
通过RouteLocator匹配 Route: getHandlerInternal方法调用lookupRoute()方法，通过routeLocator获取所有配置的route,通过里面的Predicate配置来遍历判断找出符合的Route getHandlerInternal中返回FilteringWebHandler org.springframework.cloud.gateway.handler.FilteringWebHandler: WebHandler的实现；
FilteringWebHandler被RoutePredicateHandlerMapping返回后，在DispatcherHandler中被SimpleHandlerAdapter执行handle方法； 责任链模式：获取Route的GatewayFilter数组，创建DefaultGatewayFilterChain的过滤链；链式调用GatewayFilter 3.项目结构 核心module为spring-cloud-gateway-server
actuate: 实现springboot actuator的端点，暴露route filter predicate等信息 config: 使用springboot的配置注解的各类配置类 discover：通过注册中心获取路由Route的核心功能配置类及实现类 event：实现ApplicationEvent的事件类，例如路由刷新事件RefreshRoutesEvent filter: 包含特定路由的GatewayFilterFactory，GatewayFiler以及全局的GlobalFilter handler: 包含匹配route的断言工厂AbstractRoutePredicateFactory的所有默认实现，以及核心类FilteringWebHandler及RoutePredicateHandlerMapping route：路由的定义类，及路由定位类CachingRouteLocator的所有实现，及路由定义定位类CompositeRouteDefinitionLocator的所有实现，路由存储接口RouteDefinitionRepository及其所有实现 support：工具类；如HTTP协议处理，组件名处理，日期转换等</description></item><item><title>02.reactor响应式编程学习</title><link>https://fengzhenbing.github.io/p/02.reactor%E5%93%8D%E5%BA%94%E5%BC%8F%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0/</link><pubDate>Thu, 10 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/02.reactor%E5%93%8D%E5%BA%94%E5%BC%8F%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0/</guid><description>reactor 使用 ![image (1)](https://gitee.com/fengzhenbing/picgo/raw/master/image (1).png)
Webflux 模块的名称是 spring-webflux，名称中的 Flux 来源于 Reactor 中的类 Flux。 Reactor 两个核心概念做一些澄清，一个是Mono，另一个是Flux
Flux ：表示的是包含 0 到 N 个元素的异步序列。包含三个类型 正常的包含元素的消息 序列结束的消息 序列出错的消息 Mono： 表示的是包含 0 或者 1 个元素的异步序列。该序列中同样可以包含与 Flux 相同的三种类型的消息通知。 示例代码： https://github.com/fengzhenbing/spring-cloud-gateway-demo/blob/master/demo-gateway/src/main/java/org/fzb/demo/gateway/RectorController.java</description></item><item><title>03.scg NettyWebServer启动过程</title><link>https://fengzhenbing.github.io/p/03.scg-nettywebserver%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B/</link><pubDate>Thu, 10 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/03.scg-nettywebserver%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B/</guid><description>scg NettyWebServer启动过程 spring cloud gateway(下面简称scg)依赖spring webflux, 而spring webflux依赖于reactor-netty,也就是scg启动过程中最终会启动netty做为服务器。 springboot中定义一下几种服务器：
1 启动ReactiveWebServerApplicationContext 从springboot启动开始分析
SpringApplication.run(GatewayApplication.class, args); 设置webApplicationType的值：REACTIVE还是servlet的。
public SpringApplication(ResourceLoader resourceLoader, Class&amp;lt;?&amp;gt;... primarySources) { this.resourceLoader = resourceLoader; Assert.notNull(primarySources, &amp;#34;PrimarySources must not be null&amp;#34;); this.primarySources = new LinkedHashSet&amp;lt;&amp;gt;(Arrays.asList(primarySources)); this.webApplicationType = WebApplicationType.deduceFromClasspath();//fzb 通过类路径中类，推测web应用类型：REACTIVE还是servlet的。 setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass(); } 再看deduceFromClasspath方法：判断DispatcherHandler存在还是DispatcherServlet存在
static WebApplicationType deduceFromClasspath() {//fzb 判断DispatcherHandler存在还是DispatcherServlet存在 if (ClassUtils.isPresent(WEBFLUX_INDICATOR_CLASS, null) &amp;amp;&amp;amp; !ClassUtils.isPresent(WEBMVC_INDICATOR_CLASS, null) &amp;amp;&amp;amp; !ClassUtils.isPresent(JERSEY_INDICATOR_CLASS, null)) { return WebApplicationType.REACTIVE; } for (String className : SERVLET_INDICATOR_CLASSES) { if (!</description></item><item><title>04.scg 一次请求的执行过程</title><link>https://fengzhenbing.github.io/p/04.scg-%E4%B8%80%E6%AC%A1%E8%AF%B7%E6%B1%82%E7%9A%84%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/</link><pubDate>Thu, 10 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/04.scg-%E4%B8%80%E6%AC%A1%E8%AF%B7%E6%B1%82%E7%9A%84%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/</guid><description>一次请求的执行过程</description></item><item><title>05.route路由的配置加载</title><link>https://fengzhenbing.github.io/p/05.route%E8%B7%AF%E7%94%B1%E7%9A%84%E9%85%8D%E7%BD%AE%E5%8A%A0%E8%BD%BD/</link><pubDate>Thu, 10 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/05.route%E8%B7%AF%E7%94%B1%E7%9A%84%E9%85%8D%E7%BD%AE%E5%8A%A0%E8%BD%BD/</guid><description>route路由的配置加载 主要在sprng-cloud-gateway-server的route包定义路由相关的定义，构建和加载
![路由](https://gitee.com/fengzhenbing/picgo/raw/master/image (2).png)
0.相关配置 通过springboot spi方式，springboot会启动spring.factories中配置的 org.springframework.cloud.gateway.discovery.GatewayDiscoveryClientAutoConfiguration org.springframework.boot.autoconfigure.EnableAutoConfiguration=\ org.springframework.cloud.gateway.config.GatewayAutoConfiguration,\ org.springframework.cloud.gateway.discovery.GatewayDiscoveryClientAutoConfiguration,\ ... 1.路由定义 路由定义RouteDefinition public class RouteDefinition { private String id; @NotEmpty @Valid//fzb 断言定义数组 private List&amp;lt;PredicateDefinition&amp;gt; predicates = new ArrayList&amp;lt;&amp;gt;(); @Valid//fzb 过滤器定义数组 private List&amp;lt;FilterDefinition&amp;gt; filters = new ArrayList&amp;lt;&amp;gt;(); @NotNull//fzb 路由路径 private URI uri; ... } 路由定义定位器 获取路由的定义，负责读取上述路由定义配置 RouteDefinition，最终会通过路由定义生成路由
public interface RouteDefinitionLocator { //fzb 获取路由定义对象 Flux&amp;lt;RouteDefinition&amp;gt; getRouteDefinitions(); } 有以下实现：
![image (3)](https://gitee.</description></item><item><title>06.route通过注册中心自动配置加载</title><link>https://fengzhenbing.github.io/p/06.route%E9%80%9A%E8%BF%87%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E8%87%AA%E5%8A%A8%E9%85%8D%E7%BD%AE%E5%8A%A0%E8%BD%BD/</link><pubDate>Thu, 10 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/06.route%E9%80%9A%E8%BF%87%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E8%87%AA%E5%8A%A8%E9%85%8D%E7%BD%AE%E5%8A%A0%E8%BD%BD/</guid><description>route通过注册中心Eureka自动加载配置 配置 gateway及后端微服务引入注册中心客户端eureka-client &amp;lt;!-- 引入 Spring Cloud Netflix Eureka Client 相关依赖，将 Eureka 作为注册中心的客户端，并实现对其的自动配置 --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-cloud-starter-netflix-eureka-client&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; eureka-client starter的引入，会同时引入ribbon,作为后续请求，负载均衡的实现 spring.cloud.gateway.discovery.locator.enabled设为true,启用服务发现的DiscoveryClientRouteDefinitionLocator
spring:cloud:# Spring Cloud Gateway 配置项，对应 GatewayProperties 类gateway:discovery:locator:enabled:true# default fase，设为true开启@Configuration(proxyBeanMethods = false) @ConditionalOnProperty(value = &amp;#34;spring.cloud.discovery.reactive.enabled&amp;#34;,//fzb 默认使用响应式的方式 matchIfMissing = true) public static class ReactiveDiscoveryClientRouteDefinitionLocatorConfiguration { @Bean//fzb spring.cloud.gateway.discovery.locator.enabled配为true时，才开启DiscoveryClientRouteDefinitionLocator @ConditionalOnProperty(name = &amp;#34;spring.cloud.gateway.discovery.locator.enabled&amp;#34;) public DiscoveryClientRouteDefinitionLocator discoveryClientRouteDefinitionLocator( ReactiveDiscoveryClient discoveryClient,//响应式的客服端 Eureka就是 EurekaReactiveDiscoveryClient DiscoveryLocatorProperties properties) { return new DiscoveryClientRouteDefinitionLocator(discoveryClient, properties); } } eureka-client的引入，会开启TimedSupervisorTask执行HeartbeatThread的心跳任务， 默认每隔30s一次 RouteRefreshListener 每隔30s接收到HeartBeatEvent事件，同时会发送RefreshRoutes事件</description></item><item><title>07.precidate的对路由进行选择</title><link>https://fengzhenbing.github.io/p/07.precidate%E7%9A%84%E5%AF%B9%E8%B7%AF%E7%94%B1%E8%BF%9B%E8%A1%8C%E9%80%89%E6%8B%A9/</link><pubDate>Thu, 10 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/07.precidate%E7%9A%84%E5%AF%B9%E8%B7%AF%E7%94%B1%E8%BF%9B%E8%A1%8C%E9%80%89%E6%8B%A9/</guid><description>precidate选择路由</description></item><item><title>08.filter的配置加载及合并</title><link>https://fengzhenbing.github.io/p/08.filter%E7%9A%84%E9%85%8D%E7%BD%AE%E5%8A%A0%E8%BD%BD%E5%8F%8A%E5%90%88%E5%B9%B6/</link><pubDate>Thu, 10 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/08.filter%E7%9A%84%E9%85%8D%E7%BD%AE%E5%8A%A0%E8%BD%BD%E5%8F%8A%E5%90%88%E5%B9%B6/</guid><description/></item><item><title>soul整体结构</title><link>https://fengzhenbing.github.io/p/soul%E6%95%B4%E4%BD%93%E7%BB%93%E6%9E%84/</link><pubDate>Thu, 10 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/soul%E6%95%B4%E4%BD%93%E7%BB%93%E6%9E%84/</guid><description>ShenYu介绍 官网
高性能，多协议，易扩展，响应式的API Gateway 丰富的协议 支持 dubbo ，tars， springcloud grpc。 插件化 插件化设计思想，插件热插拔，易扩展。 流控 灵活的流量筛选，能满足各种流量控制。 内置插件 内置丰富的插件支持，鉴权，限流，熔断，防火墙等。 高性能 流量配置动态化，性能极高，网关消耗在 1~2ms。 集群部署 支持集群部署，支持 A/B Test，蓝绿发布。 soul项目结构 soul-admin
soul网关管理端，配合soul-dashbord
Soul-bootstrap
网关启动工程： 实际引入soul-spring-boot-starter-gateway(soul-web)
Soul-client
为下游服务提供者提供各类服务接入网关soul的客户端
Soul-client-common Soul-client-dubbo Soul-client-grpc Soul-client-http Soul-client-sofa Soul-client-tars Soul-common
Soul-dashbord</description></item><item><title>安装redis</title><link>https://fengzhenbing.github.io/p/%E5%AE%89%E8%A3%85redis/</link><pubDate>Thu, 10 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/%E5%AE%89%E8%A3%85redis/</guid><description>下载 https://redis.io/download
编译 wget https://download.redis.io/releases/redis-6.0.10.tar.gz tar xzf redis-6.0.10.tar.gz cd redis-6.0.10 sudo make 运行 #复制配置文件及命令 mkdir ./bin mkdir ./conf sudo cp ./src/mkreleasehdr.sh ./bin sudo cp ./src/redis-benchmark ./bin sudo cp ./src/redis-check-rdb ./bin sudo cp ./src/redis-cli ./bin sudo cp ./src/redis-server ./bin sudo cp ./redis.conf ./conf #运行 ./bin/redis-server ./conf/redis.conf 配置 redis.conf
#修改为守护模式 daemonize yes #设置进程锁文件 pidfile /usr/local/redis-4.0.11/redis.pid #端口 port 6379 #客户端超时时间 timeout 300 #日志级别 loglevel debug #日志文件位置 logfile /usr/local/redis-4.0.11/log-redis.log #设置数据库的数量，默认数据库为0，可以使用SELECT &amp;lt;dbid&amp;gt;命令在连接上指定数据库id databases 16 ##指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合 #save &amp;lt;seconds&amp;gt; &amp;lt;changes&amp;gt; #Redis默认配置文件中提供了三个条件： save 900 1 save 300 10 save 60 10000 #指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间， #可以关闭该#选项，但会导致数据库文件变的巨大 rdbcompression yes #指定本地数据库文件名 dbfilename dump.</description></item><item><title>Hugo搭建博客</title><link>https://fengzhenbing.github.io/p/hugo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/</link><pubDate>Tue, 08 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/hugo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/</guid><description>通过Hugo搭建静态博客网站，再通过github pages部署运行
Hugo介绍 Hugo是一种用Go语言编写的快速，现代的静态网站生成器，旨在让网站创建再次变得有趣。 性能高，安全性和易用性是主要特点 拥有超快的速度，强大的内容管理和强大的模板语言，使其非常适合各种静态网站。 Hugo安装 # mac上安装 brew install hugo # windows可通过Chocolatey上安装 choco install hugo -confirm # 版本验证 hugo version hugo主题 查找你喜欢的主题 在此我选择的主题为toha 详情 初始化网站模板 # 首先在github下创建xxx.github.io的仓库 git clone https://github.com/fengzhenbing/fengzhenbing.github.io.git cd ./fengzhenbing.github.io # 初始化模板 hugo new site ./ -f=yaml --force #添加hugo-toha主题 git submodule add https://github.com/hugo-toha/toha.git themes/toha #本地运行 hugo server -t toha -w 修改配置 参考themes/toha/exampleSite，配置网站根目录下的config.yml文件，配置网站各个模块
baseURL:https://fengzhenbing.github.io/languageCode:en-usdefaultContentLanguage:cntitle:&amp;#34;Feng Zhenbing&amp;#39;s Blog&amp;#34;theme:&amp;#34;toha&amp;#34;# Manage languages# For any more details, you can check the official documentation: https://gohugo.</description></item><item><title>配置中心刷新</title><link>https://fengzhenbing.github.io/p/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E5%88%B7%E6%96%B0/</link><pubDate>Tue, 08 Dec 2020 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E5%88%B7%E6%96%B0/</guid><description>配置中心刷新原理 nacos和spring cloud config两种配置中心动态刷新的范围都是以下两种：
@ConfigurationProperties 注解的配置类 @RefreshScope 注解的bean 手动刷新 post请求config客户端的/refresh端点
自动刷新 WebHooks动态触发刷新
spring-cloud-bus动态刷新
这时Spring Cloud Bus做配置更新步骤如下:
提交代码触发post给Server端发送bus/refresh Server端接收到请求并发送给Spring Cloud Bus Spring Cloud bus接到消息并通知给其它客户端 其它客户端接收到通知，请求Server端获取最新配置 全部客户端均获取到最新的配置 这样的话我们在server端的代码做一些改动，来支持/actuator/bus-refresh
Spring Cloud Bus Spring Cloud Bus 使用轻量级的消息代理来连接微服务架构中的各个服务，可以将其用于广播状态更改（例如配置中心配置更改）或其他管理指令
目前 Spring Cloud Bus 支持两种消息代理：RabbitMQ 和 Kafka。
参考
https://blog.csdn.net/woshilijiuyi/article/details/88293782
https://www.cnblogs.com/babycomeon/p/11141160.html</description></item><item><title>小程序框架</title><link>https://fengzhenbing.github.io/p/%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%A1%86%E6%9E%B6/</link><pubDate>Mon, 23 Nov 2020 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%A1%86%E6%9E%B6/</guid><description>小程序原理 使用两个线程：保证平台安全性，不能让开发者控制 render 线程，控制 render 线程将会造成小程序平台方管控困难 worker线程： 用户控制 响应 render 线程的事件，并执行小程序业务逻辑。 准备好数据，通过 setData 传到 page 中，由 page 进行渲染。 render线程：接收数据渲染到页面 TARO 官网
https://taro-ui.jd.com/
特点
编译时转换
React vue &amp;hellip;
一套组件可以在 微信小程序，支付宝小程序，百度小程序，H5 多端适配运行
创建项目
# 使用 npm 安装 CLI $ npm install -g @tarojs/cli # OR 使用 yarn 安装 CLI $ yarn global add @tarojs/cli # OR 安装了 cnpm，使用 cnpm 安装 CLI $ cnpm install -g @tarojs/cli Remax 官网</description></item><item><title>kafka基础</title><link>https://fengzhenbing.github.io/p/kafka%E5%9F%BA%E7%A1%80/</link><pubDate>Tue, 20 Oct 2020 14:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/kafka%E5%9F%BA%E7%A1%80/</guid><description>kafka相关概念 二代mq, scala开发
broker topic patition producer customer Customer group leader follower rebalance 服务端partition数量扩大 消费者组中某个消费者down掉 Topic特性 通过partition增加可扩展性：线上改partion数，rebalance ，会照成性能抖动。 partition有序达到高吞吐 partition多副本增加容错性 kafka单机 安装 http://kafka.apache.org/downloads
修改配置
cd kafka_2.13-2.7.0 # 打开 listeners=PLAINTEXT://localhost:9092 vim config/server.properties # 启动zookeeper bin/zookeeper-server-start.sh config/zookeeper.properties # 启动kafaka bin/kafka-server-start.sh config/server.properties 命令测试
# 创建topic mokernetdeMac-mini:kafka_2.13-2.7.0 mokernet$ bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic testf --partitions 4 --replication-factor 1 Created topic testf. # 查看 bin/kafka-topics.</description></item><item><title>消息基础</title><link>https://fengzhenbing.github.io/p/%E6%B6%88%E6%81%AF%E5%9F%BA%E7%A1%80/</link><pubDate>Sun, 11 Oct 2020 09:16:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/%E6%B6%88%E6%81%AF%E5%9F%BA%E7%A1%80/</guid><description>消息队列作用 异步通信：异步通信，减少线程等待，特别是处理批量等大事务、耗时操作。 系统解耦:系统不直接调用，降低依赖，特别是不在线也能保持通信最终完成。 削峰填谷:压力大的时候，缓冲部分请求消息，类似于背压处理。 可靠通信:提供多种消息模式、服务质量、顺序保障等。 消息处理模式 点对点： PTP =&amp;gt; queue 发布订阅： PubSub =&amp;gt; Topic 消息语义 QOS At most once At least once Exactly once</description></item><item><title>单例</title><link>https://fengzhenbing.github.io/p/%E5%8D%95%E4%BE%8B/</link><pubDate>Fri, 21 Aug 2020 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/%E5%8D%95%E4%BE%8B/</guid><description>单例模式 在运行期间，保证某个类只创建一个实例，保证一个类仅有一个实例，并提供一个访问它的全局访问点
饿汉式 public class Singleton { private static Singleton instance = new Singleton(); private Singleton() { } public static Singleton getInstance() { return instance; } } 优点就是实现简单，而且安全可靠 缺点，没有懒加载，可能用不到，却实例化了 懒汉式 public class SingletonSafe { // 防止指令重排 private static volatile SingletonSafe singleton; private SingletonSafe() { } public static SingletonSafe getSingleton() { if (singleton == null) { synchronized (SingletonSafe.class) { if (singleton == null) { singleton = new SingletonSafe(); } } } return singleton; } } 双重检查，保证线程安全</description></item><item><title>全局事物</title><link>https://fengzhenbing.github.io/p/%E5%85%A8%E5%B1%80%E4%BA%8B%E7%89%A9/</link><pubDate>Thu, 13 Aug 2020 14:16:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/%E5%85%A8%E5%B1%80%E4%BA%8B%E7%89%A9/</guid><description>两段式提交 （2 Phase Commit，2PC）
准备阶段 重操作
提交阶段 轻操作
三段式提交 （3 Phase Commit，3PC）
在事务需要回滚的场景中：三段式的性能通常是要比两段式好很多的。
但在事务能够正常提交的场景中：两者的性能都依然很差，甚至三段式因为多了一次询问，还要稍微更差一些。
CanCommit 轻操作
PreCommit 重操作
CanCommit 轻操作</description></item><item><title>本地事务</title><link>https://fengzhenbing.github.io/p/%E6%9C%AC%E5%9C%B0%E4%BA%8B%E5%8A%A1/</link><pubDate>Wed, 12 Aug 2020 14:16:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/%E6%9C%AC%E5%9C%B0%E4%BA%8B%E5%8A%A1/</guid><description>1 介绍 本地事务（局部事务）在程序代码层面，最多只能对事务接口做一层标准化的包装（如 JDBC 接口），并不能深入参与到事务的运作过程当中，事务的开启、终止、提交、回滚、嵌套、设置隔离级别，乃至与应用代码贴近的事务传播方式，全部都要依赖底层数据源的支持才能工作。
2 原子性（A）和持久性（D） 崩溃 （Crash）：数据库、操作系统一侧的崩溃，甚至是机器突然断电宕机等意外情况。
崩溃恢复（Crash Recovery，也有资料称作 Failure Recovery 或 Transaction Recovery）:为了保证原子性和持久性，就只能在崩溃后采取恢复的补救措施
Commit Logging 为了能够顺利地完成崩溃恢复，在磁盘中写入数据就不能像程序修改内存中变量值那样，直接改变某表某行某列的某个值，而是必须将修改数据这个操作所需的全部信息，包括修改什么数据、数据物理上位于哪个内存页和磁盘块中、从什么值改成什么值，等等，以日志的形式——即仅进行顺序追加的文件写入的形式（这是最高效的写入方式）先记录到磁盘中。只有在日志记录全部都安全落盘，数据库在日志中看到代表事务成功提交的“提交记录”（Commit Record）后，才会根据日志上的信息对真正的数据进行修改，修改完成后，再在日志中加入一条“结束记录”（End Record）表示事务已完成持久化.
阿里的OceanBase 采用Commit Logging 机制来实现事务
缺点：所有对数据的真实修改都必须发生在事务提交以后，即日志写入了 Commit Record 之后。在此之前，即使磁盘 I/O 有足够空闲、即使某个事务修改的数据量非常庞大，占用了大量的内存缓冲区，无论有何种理由，都决不允许在事务提交之前就修改磁盘上的数据。
Write-Ahead Logging 按照事务提交时点为界，划分为 FORCE 和 STEAL 两类情况。
FORCE：当事务提交后，要求变动数据必须同时完成写入则称为 FORCE，如果不强制变动数据必须同时完成写入则称为 NO-FORCE。现实中绝大多数数据库采用的都是 NO-FORCE 策略，因为只要有了日志，变动数据随时可以持久化，从优化磁盘 I/O 性能考虑，没有必要强制数据写入立即进行。 STEAL：在事务提交前，允许变动数据提前写入则称为 STEAL，不允许则称为 NO-STEAL。从优化磁盘 I/O 性能考虑，允许数据提前写入，有利于利用空闲 I/O 资源，也有利于节省数据库缓存区的内存。 Write-Ahead Logging 在崩溃恢复时会执行以下三个阶段的操作：
分析阶段（Analysis）：该阶段从最后一次检查点（Checkpoint，可理解为在这个点之前所有应该持久化的变动都已安全落盘）开始扫描日志，找出所有没有 End Record 的事务，组成待恢复的事务集合，这个集合至少会包括 Transaction Table 和 Dirty Page Table 两个组成部分。 重做阶段（Redo）：该阶段依据分析阶段中产生的待恢复的事务集合来重演历史（Repeat History），具体操作为：找出所有包含 Commit Record 的日志，将这些日志修改的数据写入磁盘，写入完成后在日志中增加一条 End Record，然后移除出待恢复事务集合。 回滚阶段（Undo）：该阶段处理经过分析、重做阶段后剩余的恢复事务集合，此时剩下的都是需要回滚的事务，它们被称为 Loser，根据 Undo Log 中的信息，将已经提前写入磁盘的信息重新改写回去，以达到回滚这些 Loser 事务的目的。 Shadow Paging 副本方式</description></item><item><title>高可用之限流</title><link>https://fengzhenbing.github.io/p/%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B9%8B%E9%99%90%E6%B5%81/</link><pubDate>Sun, 21 Jun 2020 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B9%8B%E9%99%90%E6%B5%81/</guid><description>限流算法 固定窗口计数器 将时间划分为多个窗口； 在每个窗口内每有一次请求就将计数器加一； 如果计数器超过了限制数量，则本窗口内所有的请求都被丢弃当时间到达下一个窗口时，计数器重置。 问题：可能有时会让通过请求量允许为限制的两倍
举例：限制 1 秒内最多通过 5 个请求，在第一个窗口的最后半秒内通过了 5 个请求，第二个窗口的前半秒内又通过了 5 个请求。这样看来就是在 1 秒内通过了 10 个请求
滑动窗口计数器 一个窗口多个区间，每次滑动一个区间
将时间划分为多个区间；
在每个区间内每有一次请求就将计数器加一维持一个时间窗口，占据多个区间；
每经过一个区间的时间，则抛弃最老的一个区间，并纳入最新的一个区间；
如果当前窗口内区间的请求计数总和超过了限制数量，则本窗口内所有的请求都被丢弃。
滑动窗口计数器是通过将窗口再细分，并且按照时间&amp;quot;滑动&amp;quot;，这种算法避免了固定窗口计数器带来的双倍突发请求，但时间区间的精度越高，算法所需的空间容量就越大。
漏桶 将每个请求视作&amp;quot;水滴&amp;quot;放入&amp;quot;漏桶&amp;quot;进行存储； “漏桶&amp;quot;以固定速率向外&amp;quot;漏&amp;quot;出请求来执行如果&amp;quot;漏桶&amp;quot;空了则停止&amp;quot;漏水”； 如果&amp;quot;漏桶&amp;quot;满了则多余的&amp;quot;水滴&amp;quot;会被直接丢弃。 漏桶算法多使用队列实现，服务的请求会存到队列中，服务的提供方则按照固定的速率从队列中取出请求并执行，过多的请求则放在队列中排队或直接拒绝。
漏桶算法的缺陷也很明显，当短时间内有大量的突发请求时，即便此时服务器没有任何负载，每个请求也都得在队列中等待一段时间才能被响应。
令牌桶（推荐） 令牌以固定速率生成； 生成的令牌放入令牌桶中存放，如果令牌桶满了则多余的令牌会直接丢弃，当请求到达时，会尝试从令牌桶中取令牌，取到了令牌的请求可以执行； 如果桶空了，那么尝试取令牌的请求会被直接丢弃。 参考https://mp.weixin.qq.com/s?__biz=MzkwOTIxNDQ3OA==&amp;amp;mid=2247532784&amp;amp;idx=1&amp;amp;sn=4105e55673af275ea26701cb6070ab48&amp;amp;source=41#wechat_redirect</description></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description>系统调用 用户态(user mode) : 用户态运行的进程可以直接读取用户程序的数据。 系统态(kernel mode):可以简单的理解系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制。 凡是与系统态级别的资源有关的操作（如文件管理、进程控制、内存管理等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。
进程的调度算法 先到先服务(FCFS)调度算法 短作业优先(SJF)的调度算法 时间片轮转调度算法 多级反馈队列调度算法 优先级调度 死锁 必要条件
互斥：资源必须处于非共享模式，即一次只有一个进程可以使用。如果另一进程申请该资源，那么必须等待直到该资源被释放为止。
占有并等待：一个进程至少应该占有一个资源，并等待另一资源，而该资源被其他进程所占有。
非抢占：资源不能被抢占。只能在持有资源的进程完成任务后，该资源才会被释放。
循环等待：有一组等待进程 {P0, P1,..., Pn}， P0 等待的资源被 P1 占有，P1 等待的资源被 P2 占有，&amp;hellip;&amp;hellip;，Pn-1 等待的资源被 Pn 占有，Pn 等待的资源被 P0 占有。
虚拟内存 虚拟内存的重要意义是它定义了一个连续的虚拟地址空间，并且 把内存扩展到硬盘空间。
局部性原理 时间局部性 ：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。 空间局部性 ：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。</description></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description>什么事JMM JMM 规范明确定义了不同的线程之 间，通过哪些方式，在什么时候可以 看见其他线程保存到共享变量中的 值;以及在必要时，如何对共享变量 的访问进行同步。这样的好处是屏蔽 各种硬件平台和操作系统之间的内存 访问差异，实现了 Java 并发程序真 正的跨平台。</description></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description/></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description/></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description/></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description/></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description/></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description/></item></channel></rss>