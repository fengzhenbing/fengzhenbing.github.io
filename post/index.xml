<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Feng Zhenbing's Blog</title><link>https://fengzhenbing.github.io/post/</link><description>Recent content in Posts on Feng Zhenbing's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 05 Sep 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://fengzhenbing.github.io/post/index.xml" rel="self" type="application/rss+xml"/><item><title>shardingsphere（5.0.0.beta）元数据上下文</title><link>https://fengzhenbing.github.io/p/shardingsphere5.0.0.beta%E5%85%83%E6%95%B0%E6%8D%AE%E4%B8%8A%E4%B8%8B%E6%96%87/</link><pubDate>Sun, 05 Sep 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/shardingsphere5.0.0.beta%E5%85%83%E6%95%B0%E6%8D%AE%E4%B8%8A%E4%B8%8B%E6%96%87/</guid><description>Shardingsphere（5.0.0.beta）源码学习-元数据上下文 上下文对象 上下文对象作为读取并解析配置, 承载数据的核心；
spring有ApplicationContext,netty有HandlerContext
向其他中间件一样，在ShardingSphere也十分重要; 后续几乎所有功能比如数据分片、数据加密、SQL 改写，各类扩展都依赖上下文对象存储的数据
标准元数据上下文 StandardMetaDataContexts 核心存储了ShardingSphereMetaData元数据集合，作为重点后面分析
@Getter public final class StandardMetaDataContexts implements MetaDataContexts { // 元数据集合 private final Map&amp;lt;String, ShardingSphereMetaData&amp;gt; metaDataMap; private final ShardingSphereRuleMetaData globalRuleMetaData; // 执行引擎 private final ExecutorEngine executorEngine; //优化引擎上下文工厂 private final OptimizeContextFactory optimizeContextFactory; private final ConfigurationProperties props; // 状态上下文 private final StateContext stateContext; ... } 治理元数据上下文 StandardMetaDataContexts 其实也是用的标准的StandardMetaDataContexts，治理模块shardingsphere-governance使用该上下文，通过配置中心读取规则配置，
注入到StandardMetaDataContexts中，GovernanceFacade是配置中心的门面模式，目前支持了zookeeper和etcd,其实还可以通过RegistryCenterRepository的spi实现其他的配置中心，比如nacos, apollo,consul等。
public final class GovernanceMetaDataContexts implements MetaDataContexts { //治理： 配置中心的门面模式 private final GovernanceFacade governanceFacade; //还是使用StandardMetaDataContexts 装饰器模式 private volatile StandardMetaDataContexts metaDataContexts; private final ShardingSphereLock lock; .</description></item><item><title>shardingsphere（5.0.0.beta）源码总览</title><link>https://fengzhenbing.github.io/p/shardingsphere5.0.0.beta%E6%BA%90%E7%A0%81%E6%80%BB%E8%A7%88/</link><pubDate>Thu, 02 Sep 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/shardingsphere5.0.0.beta%E6%BA%90%E7%A0%81%E6%80%BB%E8%A7%88/</guid><description>Shardingsphere（5.0.0.beta）源码学习-总览 shardingsphere作为极为优秀的开源分布式数据库解决方案，通过阅读源码可以学到很多软件设计与开发的知识。
本次我继续按照之前读源码的方式从整体到细节，带着问题读源码的方式记录这次深入学习 shardingsphere的过程。
源码版本 5.0.0.beta 官方文档 源码地址 https://github.com/apache/shardingsphere/tree/5.0.0-beta 项目结构 先大概理解各个模块的主要功能点
一级目录 说明 examples 各种使用例子 shardingsphere-agent 监控, 对接apm,链路追踪 shardingsphere-db-protocol 数据库协议 shardingsphere-distribution 相关打包发步用 shardingsphere-distsql-parser distsql新功能:ShardingSphere 特有的内置 SQL 语言，提供了标准 SQL 之外的增量功能操作能力。 shardingsphere-features 常用功能shardingsphere-db-discovery 基于MGR主从切换的功能shardingsphere-encrypt 加解密shardingsphere-readwrite-splitting 读写分离 **重点**shardingsphere-shadow 影子库shardingsphere-sharding 分库分表 **重点** shardingsphere-governance 数据治理：结合注册中心，提供给前端页面使用 shardingsphere-infra 引擎内核：shardingsphere-infra-authority proxy的权限控制shardingsphere-infra-binder sql解析后的结果绑定封装SQLStatement封装为各类上下文contextshardingsphere-infra-common 重要的实体类及工具 的元数据metadata,SPI,yaml工具，rule接口等shardingsphere-infra-context 上下文相关shardingsphere-infra-datetime 时间服务shardingsphere-infra-executor 执行器引擎 **重点**shardingsphere-infra-merge 归并引擎**重点**shardingsphere-infra-optimize 优化引擎**重点**shardingsphere-infra-parser 解析引擎**重点**shardingsphere-infra-rewrite 改写引擎**重点**shardingsphere-infra-route 路由引擎**重点** shardingsphere-jdbc jdbc核心功能：增强版的 JDBC 驱动，完全兼容 JDBC 和各种 ORM 框架。装饰器模式，对原生的DataSource,Connection,Statement(PrepareStatement),ResultSet进行包装， shardingsphere-proxy 透明化的数据库代理提供封装了数据库二进制协议的服务端版本，用于完成对异构语言的支持 shardingsphere-scaling 数据迁移相关:弹性伸缩 shardingsphere-sql-parser sql解析器：antlr4 词法语法解析出SqlStatement,提供各类数据库的方言实现。SQL 解析作为分库分表类产品的核心，其性能和兼容性是最重要的衡量指标 shardingsphere-test 测试引擎 shardingsphere-transaction 事务：整合现有的成熟事务方案，本地事务、两阶段事务（XA）和柔性事务（Seata AT 事务）提供统一的分布式事务接口 对于重点核心内容有个大致认识，后面再单独分模块分析。</description></item><item><title>分布式任务调度Hodor</title><link>https://fengzhenbing.github.io/p/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6hodor/</link><pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6hodor/</guid><description>分布式任务调度Hodor源码分析（整体结构） 简介 Hodor是一个高性能的分布式任务调度框架。
github地址(https://github.com/tincopper/hodor)
架构图 因无任何文档，以下架构图纯阅读源码个人理解后手工所画：
代码目录及分析 hodor-admin
待开发：配合前端页面做任务展示
hodor-client
客户端，用户app通过该客户端将任务信息提交到hodor-server，供其调度
集成了nettyserver服务，接收来自hodor-server的任务执行请求
hodor-client-demo
用户app示例：集成了hodor-client
hodor-common
通用库
环形队列 观察者模式（事件发布监听）模型 Excutor：多线程封装 Extension: SPI扩展方式封装 负载均衡 存储：本地缓存/mysql/h2 异常 日志 Distributor高性能队列 hodor-core
简单的spring mybatis 工程：对任务/任务执行记录等数据入库（mysql）
hodor-extension
hodor-model
实体
hodor-register
注册中心封装，目前只实现了zookeeper
hodor-register-api Hodor-register-zookeeper hodor-remoting
netty http客户端
netty http服务端
hodor-scheduler
任务定时的封装</description></item><item><title>docusaurus构建website</title><link>https://fengzhenbing.github.io/p/docusaurus%E6%9E%84%E5%BB%BAwebsite/</link><pubDate>Sun, 22 Aug 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/docusaurus%E6%9E%84%E5%BB%BAwebsite/</guid><description>docusaurus构建website 环境 Node.js version &amp;gt;= 12.13.0 以上(node -v 查看)，使用了国际化i18n，则Node.js version &amp;gt;=14以上
Yarn version &amp;gt;= 1.5 ( yarn &amp;ndash;version查看). mac下可以使用n管理node版本
Title logo等文案，首页展示 待讨论
菜单调整 Nav : 文档 社区 新闻 博客 links 国际化切换 搜索
Documentation Community News Blog Links
Footer:
首页 下载按钮 文档按钮 star按钮修改
样式修改
国际化语言 yarn write-translations --locale zh 参考https://docusaurus.io/zh-CN/docs/cli#docusaurus-write-translations-sitedir
中英文两个版本的文件名称保持一致。文档中没有指定sidebar_position时，默认按文件名称在菜单栏排序</description></item><item><title>开放平台appKey，appSecret设计</title><link>https://fengzhenbing.github.io/p/%E5%BC%80%E6%94%BE%E5%B9%B3%E5%8F%B0appkeyappsecret%E8%AE%BE%E8%AE%A1/</link><pubDate>Thu, 19 Aug 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/%E5%BC%80%E6%94%BE%E5%B9%B3%E5%8F%B0appkeyappsecret%E8%AE%BE%E8%AE%A1/</guid><description>开放平台appKey appSecret设计 1，手动注册客户端，服务端返回appKey appSecret 客户端和服务端都保存ak as 2, 客户端第一次请求 通过appKey请求token 服务端通过appKey，appSecret，时间戳，用户的必要信息生成token，可以使用JWTToken.
​ token具有有效期：Token是客户端访问服务端的凭证。
3，客户端后续请求 参数为： Token + 当前时间戳 + 参数 +签名sign1
签名sign1为 Token + 当前时间戳 + 参数+appSecret 按照一定签名算法比如 SHA256生成的签名字符串，为了保证请求中参数不被流量劫持篡改
4，服务端收到请求进行校验 时间戳校验：请求时间和当前服务端时间大于一定范围，比如5分钟，拒绝执行 Token解析：token过期拒绝执行 签名校验： 通过token解析获取到appKey，再获取到appSecret， 使用与客户端相同的签名算法SHA256得到签名sign2, 如果sign1不等于sign2，拒绝执行</description></item><item><title>Prometheus监控JVM</title><link>https://fengzhenbing.github.io/p/prometheus%E7%9B%91%E6%8E%A7jvm/</link><pubDate>Sun, 15 Aug 2021 14:16:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/prometheus%E7%9B%91%E6%8E%A7jvm/</guid><description>1. jmx_exporter 下载jmx_exporter ubuntu:/# mkdir -p /usr/local/prometheus/jmx_exporter ubuntu:/# cd /usr/local/prometheus/jmx_exporter ubuntu:/# wget https://repo1.maven.org/maven2/io/prometheus/jmx/jmx_prometheus_javaagent/0.16.1/jmx_prometheus_javaagent-0.16.1.jar 配置文件jmx_exporter jmx_exporter.yml
vim /usr/local/prometheus/jmx_exporter/jmx_exporter.yml --- rules: - pattern: &amp;quot;.*&amp;quot; java agent运行jmx_exporter 以java agent的方式启动你的一个java应用
java -javaagent:/usr/local/prometheus/jmx_prometheus_javaagent-0.16.1.jar=3010:/usr/local/prometheus/jmx_exporter.yml -jar xxx-web-0.1-SNAPSHOT.jar 2. prometheus docker方式下载运行 # docker pull prom/prometheus #下载docker镜像 # mkdir -p /etc/prometheus # vim /etc/prometheus/prometheus.yml #配置 # docker run -d \ -p 192.168.3.13:9090:9090 \ -v /etc/prometheus:/etc/prometheus \ prom/prometheus; prometheus中配置上步的jmx的metrics global:scrape_interval:15sscrape_timeout:10sevaluation_interval:15salerting:alertmanagers:- follow_redirects:truescheme:httptimeout:10sapi_version:v2static_configs:- targets:[]scrape_configs:- job_name:prometheushonor_timestamps:truescrape_interval:15sscrape_timeout:10smetrics_path:/metricsscheme:httpfollow_redirects:truestatic_configs:- targets:- 192.168.3.13:9090### 以下为jmx_exporter地址：需改为你实际的- job_name:&amp;#39;jmx&amp;#39;static_configs:scrape_interval:15s- targets:[&amp;#39;192.</description></item><item><title>mac下node升级</title><link>https://fengzhenbing.github.io/p/mac%E4%B8%8Bnode%E5%8D%87%E7%BA%A7/</link><pubDate>Wed, 21 Jul 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/mac%E4%B8%8Bnode%E5%8D%87%E7%BA%A7/</guid><description># 清除nodejs的cache sudo npm cache clean -f # 由于您可能已经拥有node，最简单的安装方式n是npm： sudo npm install -g n # node所有版本 npm view node versions # 升级到最新版本 sudo n latest # 升级到稳定版本 sudo n stable # 升级到具体版本号 sudo n xx.xx</description></item><item><title>加密算法</title><link>https://fengzhenbing.github.io/p/%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/</link><pubDate>Mon, 21 Jun 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/</guid><description>哈希摘要算法 好的哈希摘要算法需要具备
一是易变性，这是指算法的输入端发生了任何一点细微变动，都会引发雪崩效应,使得输出端的结果产生极大的变化
常常被用来校验数据是否被篡改
二是不可逆性，摘要的过程是单向的，不可能从摘要的结果中逆向还原出输入值来
对称加密和非对称加密 对称加密 对称加密指的就是加密和解密使用同一个秘钥，所以叫做对称加密。对称加密只有一个秘钥，作为私钥。 常见的对称加密算法：DES，3DES，AES等等。
非对称加密 非对称加密指的是：加密和解密使用不同的秘钥，一把作为公开的公钥，另一把作为私钥。公钥加密的信息，只有私钥才能解密。私钥加密的信息，只有公钥才能解密。 常见的非对称加密算法：RSA，ECC
区别 对称加密算法相比非对称加密算法来说，加解密的效率要高得多。但是缺陷在于对于秘钥的管理上，以及在非安全信道中通讯时，密钥交换的安全性不能保障。所以在实际的网络环境中，会将两者混合使用.
对称加密传输大量数据
非对称加密永远对称加密的密钥协商，传输。
例如针对C/S模型，
服务端计算出一对秘钥pub/pri。将私钥保密，将公钥公开。 客户端请求服务端时，拿到服务端的公钥pub。 客户端通过AES计算出一个对称加密的秘钥X。 然后使用pub将X进行加密。 客户端将加密后的密文发送给服务端。服务端通过pri解密获得X。 然后两边的通讯内容就通过对称密钥X以对称加密算法来加解密。
三种密码学算法的对比 类型 特点 常见实现 主要用途 主要局限 哈希摘要 不可逆，即不能解密，所以并不是加密算法，只是一些场景把它当作加密算法使用。 易变性，输入发生 1 Bit 变动，就可能导致输出结果 50%的内容发生改变。 无论输入长度多少，输出长度固定（2 的 N 次幂）。 MD2/4/5/6、SHA0/1/256/512 摘要 无法解密 对称加密 加密是指加密和解密是一样的密钥。 设计难度相对较小，执行速度相对较块。 加密明文长度不受限制。 DES、AES、RC4、IDEA 加密 要解决如何把密钥安全地传递给解密者。 非对称加密 加密和解密使用的是不同的密钥。 明文长度不能超过公钥长度。 RSA、BCDSA、ElGamal 签名、传递密钥 性能与加密明文长度受限。 数字证书 解决公钥被劫持篡改的问题。由权威机构颁发保证</description></item><item><title>jvm垃圾回收</title><link>https://fengzhenbing.github.io/p/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/</link><pubDate>Sun, 14 Mar 2021 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/</guid><description>jvm垃圾回收 对象存活判断算法 引用计数算法 问题： 可能存在两个对象相互引用，导致无法回收，内存泄漏
根可达算法 维护引用的链表； 如果某个对象无法到达根节点，说明可以被回收
垃圾回收算法 对停顿时间(延时)和吞吐量的权衡，没有最好，只有最适合当前业务场景的回收方式
针对 堆内存回收；
方法区
java 8 前 永久区（也参与垃圾回收，一样的算法，省事了，但是有默认最大内存限制，容易oom） java 8 彻底抛弃了 永久区，叫元数据区，使用本地内存 分代收集理论 新生代
老年代
跨代引用： Remember set
标记清除 产生内存碎片，内存分配复杂了。 可能需要类似硬盘的 “分区空闲分配链表” 等复杂方式解决
Cms搜集器在old 区回收时采用， 但是内存碎片达到一定量，会采取一次标记整理。（和稀泥的做法，结合两者，）
标记复制 一般用于新生代回收: Serial ParNew 的新生代采用该算法
scurvivorRadio Ēden survivor survivor 8:1:1
对象存活率较高时，需要更多的复制操作，效率会降低
标记整理 用于old区：
相对于 标记清除， 标记后，需要移动：将存活的对象移动到内存区域的一端。
移动：增大的延迟，stw时间长些，但解决了内存碎片，内存分配复杂的问题，可以提高吞吐量。
不移动：降低了延迟，但内存碎片，内存分配复杂， 吞吐量有所下降。
垃圾回收器 对于新生代一般时使用标记复制算法</description></item><item><title>Hugo搭建博客</title><link>https://fengzhenbing.github.io/p/hugo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/</link><pubDate>Tue, 08 Dec 2020 08:06:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/hugo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/</guid><description>通过Hugo搭建静态博客网站，再通过github pages部署运行
Hugo介绍 Hugo是一种用Go语言编写的快速，现代的静态网站生成器，旨在让网站创建再次变得有趣。 性能高，安全性和易用性是主要特点 拥有超快的速度，强大的内容管理和强大的模板语言，使其非常适合各种静态网站。 Hugo安装 # mac上安装 brew install hugo # windows可通过Chocolatey上安装 choco install hugo -confirm # 版本验证 hugo version hugo主题 查找你喜欢的主题 在此我选择的主题为toha 详情 初始化网站模板 # 首先在github下创建xxx.github.io的仓库 git clone https://github.com/fengzhenbing/fengzhenbing.github.io.git cd ./fengzhenbing.github.io # 初始化模板 hugo new site ./ -f=yaml --force #添加hugo-toha主题 git submodule add https://github.com/hugo-toha/toha.git themes/toha #本地运行 hugo server -t toha -w 修改配置 参考themes/toha/exampleSite，配置网站根目录下的config.yml文件，配置网站各个模块
baseURL:https://fengzhenbing.github.io/languageCode:en-usdefaultContentLanguage:cntitle:&amp;#34;Feng Zhenbing&amp;#39;s Blog&amp;#34;theme:&amp;#34;toha&amp;#34;# Manage languages# For any more details, you can check the official documentation: https://gohugo.</description></item><item><title>单例</title><link>https://fengzhenbing.github.io/p/%E5%8D%95%E4%BE%8B/</link><pubDate>Fri, 21 Aug 2020 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/%E5%8D%95%E4%BE%8B/</guid><description>单例模式 在运行期间，保证某个类只创建一个实例，保证一个类仅有一个实例，并提供一个访问它的全局访问点
饿汉式 public class Singleton { private static Singleton instance = new Singleton(); private Singleton() { } public static Singleton getInstance() { return instance; } } 优点就是实现简单，而且安全可靠 缺点，没有懒加载，可能用不到，却实例化了 懒汉式 public class SingletonSafe { // 防止指令重排 private static volatile SingletonSafe singleton; private SingletonSafe() { } public static SingletonSafe getSingleton() { if (singleton == null) { synchronized (SingletonSafe.class) { if (singleton == null) { singleton = new SingletonSafe(); } } } return singleton; } } 双重检查，保证线程安全</description></item><item><title>全局事物</title><link>https://fengzhenbing.github.io/p/%E5%85%A8%E5%B1%80%E4%BA%8B%E7%89%A9/</link><pubDate>Thu, 13 Aug 2020 14:16:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/%E5%85%A8%E5%B1%80%E4%BA%8B%E7%89%A9/</guid><description>两段式提交 （2 Phase Commit，2PC）
准备阶段 重操作
提交阶段 轻操作
三段式提交 （3 Phase Commit，3PC）
在事务需要回滚的场景中：三段式的性能通常是要比两段式好很多的。
但在事务能够正常提交的场景中：两者的性能都依然很差，甚至三段式因为多了一次询问，还要稍微更差一些。
CanCommit 轻操作
PreCommit 重操作
CanCommit 轻操作</description></item><item><title>本地事务</title><link>https://fengzhenbing.github.io/p/%E6%9C%AC%E5%9C%B0%E4%BA%8B%E5%8A%A1/</link><pubDate>Wed, 12 Aug 2020 14:16:25 +0600</pubDate><guid>https://fengzhenbing.github.io/p/%E6%9C%AC%E5%9C%B0%E4%BA%8B%E5%8A%A1/</guid><description>1 介绍 本地事务（局部事务）在程序代码层面，最多只能对事务接口做一层标准化的包装（如 JDBC 接口），并不能深入参与到事务的运作过程当中，事务的开启、终止、提交、回滚、嵌套、设置隔离级别，乃至与应用代码贴近的事务传播方式，全部都要依赖底层数据源的支持才能工作。
2 原子性（A）和持久性（D） 崩溃 （Crash）：数据库、操作系统一侧的崩溃，甚至是机器突然断电宕机等意外情况。
崩溃恢复（Crash Recovery，也有资料称作 Failure Recovery 或 Transaction Recovery）:为了保证原子性和持久性，就只能在崩溃后采取恢复的补救措施
Commit Logging 为了能够顺利地完成崩溃恢复，在磁盘中写入数据就不能像程序修改内存中变量值那样，直接改变某表某行某列的某个值，而是必须将修改数据这个操作所需的全部信息，包括修改什么数据、数据物理上位于哪个内存页和磁盘块中、从什么值改成什么值，等等，以日志的形式——即仅进行顺序追加的文件写入的形式（这是最高效的写入方式）先记录到磁盘中。只有在日志记录全部都安全落盘，数据库在日志中看到代表事务成功提交的“提交记录”（Commit Record）后，才会根据日志上的信息对真正的数据进行修改，修改完成后，再在日志中加入一条“结束记录”（End Record）表示事务已完成持久化.
阿里的OceanBase 采用Commit Logging 机制来实现事务
缺点：所有对数据的真实修改都必须发生在事务提交以后，即日志写入了 Commit Record 之后。在此之前，即使磁盘 I/O 有足够空闲、即使某个事务修改的数据量非常庞大，占用了大量的内存缓冲区，无论有何种理由，都决不允许在事务提交之前就修改磁盘上的数据。
Write-Ahead Logging 按照事务提交时点为界，划分为 FORCE 和 STEAL 两类情况。
FORCE：当事务提交后，要求变动数据必须同时完成写入则称为 FORCE，如果不强制变动数据必须同时完成写入则称为 NO-FORCE。现实中绝大多数数据库采用的都是 NO-FORCE 策略，因为只要有了日志，变动数据随时可以持久化，从优化磁盘 I/O 性能考虑，没有必要强制数据写入立即进行。 STEAL：在事务提交前，允许变动数据提前写入则称为 STEAL，不允许则称为 NO-STEAL。从优化磁盘 I/O 性能考虑，允许数据提前写入，有利于利用空闲 I/O 资源，也有利于节省数据库缓存区的内存。 Write-Ahead Logging 在崩溃恢复时会执行以下三个阶段的操作：
分析阶段（Analysis）：该阶段从最后一次检查点（Checkpoint，可理解为在这个点之前所有应该持久化的变动都已安全落盘）开始扫描日志，找出所有没有 End Record 的事务，组成待恢复的事务集合，这个集合至少会包括 Transaction Table 和 Dirty Page Table 两个组成部分。 重做阶段（Redo）：该阶段依据分析阶段中产生的待恢复的事务集合来重演历史（Repeat History），具体操作为：找出所有包含 Commit Record 的日志，将这些日志修改的数据写入磁盘，写入完成后在日志中增加一条 End Record，然后移除出待恢复事务集合。 回滚阶段（Undo）：该阶段处理经过分析、重做阶段后剩余的恢复事务集合，此时剩下的都是需要回滚的事务，它们被称为 Loser，根据 Undo Log 中的信息，将已经提前写入磁盘的信息重新改写回去，以达到回滚这些 Loser 事务的目的。 Shadow Paging 副本方式</description></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description>限流算法 固定窗口计数器 将时间划分为多个窗口； 在每个窗口内每有一次请求就将计数器加一； 如果计数器超过了限制数量，则本窗口内所有的请求都被丢弃当时间到达下一个窗口时，计数器重置。 问题：可能有时会让通过请求量允许为限制的两倍
举例：限制 1 秒内最多通过 5 个请求，在第一个窗口的最后半秒内通过了 5 个请求，第二个窗口的前半秒内又通过了 5 个请求。这样看来就是在 1 秒内通过了 10 个请求
滑动窗口计数器 一个窗口多个区间，每次滑动一个区间
将时间划分为多个区间；
在每个区间内每有一次请求就将计数器加一维持一个时间窗口，占据多个区间；
每经过一个区间的时间，则抛弃最老的一个区间，并纳入最新的一个区间；
如果当前窗口内区间的请求计数总和超过了限制数量，则本窗口内所有的请求都被丢弃。
滑动窗口计数器是通过将窗口再细分，并且按照时间&amp;quot;滑动&amp;quot;，这种算法避免了固定窗口计数器带来的双倍突发请求，但时间区间的精度越高，算法所需的空间容量就越大。
漏桶 将每个请求视作&amp;quot;水滴&amp;quot;放入&amp;quot;漏桶&amp;quot;进行存储； “漏桶&amp;quot;以固定速率向外&amp;quot;漏&amp;quot;出请求来执行如果&amp;quot;漏桶&amp;quot;空了则停止&amp;quot;漏水”； 如果&amp;quot;漏桶&amp;quot;满了则多余的&amp;quot;水滴&amp;quot;会被直接丢弃。 漏桶算法多使用队列实现，服务的请求会存到队列中，服务的提供方则按照固定的速率从队列中取出请求并执行，过多的请求则放在队列中排队或直接拒绝。
漏桶算法的缺陷也很明显，当短时间内有大量的突发请求时，即便此时服务器没有任何负载，每个请求也都得在队列中等待一段时间才能被响应。
令牌桶（推荐） 令牌以固定速率生成； 生成的令牌放入令牌桶中存放，如果令牌桶满了则多余的令牌会直接丢弃，当请求到达时，会尝试从令牌桶中取令牌，取到了令牌的请求可以执行； 如果桶空了，那么尝试取令牌的请求会被直接丢弃。 参考https://mp.weixin.qq.com/s?__biz=MzkwOTIxNDQ3OA==&amp;amp;mid=2247532784&amp;amp;idx=1&amp;amp;sn=4105e55673af275ea26701cb6070ab48&amp;amp;source=41#wechat_redirect</description></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description/></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description/></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description/></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description/></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description/></item><item><title/><link>https://fengzhenbing.github.io/p/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fengzhenbing.github.io/p/</guid><description/></item></channel></rss>